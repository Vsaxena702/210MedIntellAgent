{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "46e47345805e417ca4f3782b9dcdb327": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_42b6a0d83c4d4ee1892fba444dc58ea1",
              "IPY_MODEL_51b27227538e404dad2a2e6b061cf6ac",
              "IPY_MODEL_195f81195f21411dbf4f218d1dfef17b"
            ],
            "layout": "IPY_MODEL_de1e507d5d324a51867ab558c5323aa4"
          }
        },
        "42b6a0d83c4d4ee1892fba444dc58ea1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_795ec8bef88745a0843733b5a03246fd",
            "placeholder": "​",
            "style": "IPY_MODEL_7a231ac36a3145b9b286d5aa04cce0ed",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "51b27227538e404dad2a2e6b061cf6ac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_64efd766516447fab775019f7a4b3372",
            "max": 11,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d867931fc8d64e08bbb6389da4a15f0a",
            "value": 11
          }
        },
        "195f81195f21411dbf4f218d1dfef17b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e337e1fa29fa4f66b10f956e3745dc81",
            "placeholder": "​",
            "style": "IPY_MODEL_68641c77c3654a2cb4f4c553c63aa43f",
            "value": " 11/11 [03:55&lt;00:00, 21.29s/it]"
          }
        },
        "de1e507d5d324a51867ab558c5323aa4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "795ec8bef88745a0843733b5a03246fd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7a231ac36a3145b9b286d5aa04cce0ed": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "64efd766516447fab775019f7a4b3372": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d867931fc8d64e08bbb6389da4a15f0a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e337e1fa29fa4f66b10f956e3745dc81": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "68641c77c3654a2cb4f4c553c63aa43f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Lets do few shot inference against our EHR FHIR PostGre SQL database\n",
        "\n",
        "\n",
        "\n",
        "1.   Load and test Open AI access\n",
        "2.   Load and test EHR PostgreSQL database access\n",
        "3.   Load FAISS\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "MV9wJC-4l304"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 0. Mount drive and define paths"
      ],
      "metadata": {
        "id": "Q9jnuet7mr0H"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Installs"
      ],
      "metadata": {
        "id": "tH7tRQyUAvtk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "# Clean Install/Upgrade for ALL Core LLM/QLoRA Libraries\n",
        "# -U ensures the latest versions (best compatibility)\n",
        "# -q suppresses the long output\n",
        "!pip install -U -q accelerate peft transformers trl bitsandbytes sentencepiece"
      ],
      "metadata": {
        "id": "-_y71P7gYJEG"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "# --- 1) Install libraries (once per runtime) ---\n",
        "!pip -q install --upgrade openai langchain langchain-community langchain-openai faiss-cpu"
      ],
      "metadata": {
        "id": "efAQ3VfKYMY6"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "DqLwQj6Sj7TA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 0) Mount Drive and set your variables ---\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "DEV_PATH = \"/content/drive/MyDrive/210_Capstone/210_Factory/210_dev\"\n",
        "FAISS_DB_PATH = DEV_PATH + \"/vectorstores/medintellagent_faiss_v1\"\n",
        "POSTGRES_DB_PATH = DEV_PATH + \"/synthea_ehr_backup.sql\"  # (dump file; not used in this snippet)\n",
        "LLM_MODEL = \"gpt-4o-mini\"\n",
        "EMBEDDING_MODEL = \"text-embedding-3-large\"\n",
        "\n"
      ],
      "metadata": {
        "id": "c4TBeJ5kmxRS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "df2bbcda-cc0d-4f92-e55e-7c942f5cecd0"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 2) Load your OpenAI key (recommended: Colab \"Secrets\" → OPENAI_API_KEY) ---\n",
        "import os\n",
        "try:\n",
        "    from google.colab import userdata\n",
        "    key = userdata.get('OPENAI_API_KEY')\n",
        "    if key: os.environ['OPENAI_API_KEY'] = key\n",
        "except Exception:\n",
        "    pass\n",
        "\n",
        "if not os.environ.get(\"OPENAI_API_KEY\"):\n",
        "    import getpass\n",
        "    os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"Enter OPENAI_API_KEY: \")\n",
        "\n",
        "# Initialize OpenAI client\n",
        "from openai import OpenAI\n",
        "client = OpenAI()\n"
      ],
      "metadata": {
        "id": "VkoYMnoeVee1"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 3) Load  FAISS vector store (must use same embedding model used to build it) ---\n",
        "from langchain_openai import OpenAIEmbeddings\n",
        "from langchain_community.vectorstores import FAISS\n",
        "\n",
        "embeddings = OpenAIEmbeddings(model=EMBEDDING_MODEL)\n",
        "vs = FAISS.load_local(FAISS_DB_PATH, embeddings, allow_dangerous_deserialization=True)\n",
        "\n",
        "print(\"FAISS loaded. Example count:\", len(vs.docstore._dict))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9u-gdl-5VgOR",
        "outputId": "7d1922c6-6cd5-4ca6-9f09-1b33db9014a8"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FAISS loaded. Example count: 90\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Prompt building helpers ---\n",
        "\n",
        "# Keep this aligned to your actual DB schema + rules\n",
        "PREFIX = (\n",
        "    \"Return a single PostgreSQL SELECT only.\\n\"\n",
        "    \"Use only tables: patients, encounters, conditions, observations, medication_requests, procedures.\\n\"\n",
        "    \"Use only parameter :patient_id. Prefer DISTINCT ON with ORDER BY for 'latest per X'; no CTEs or window functions.\\n\"\n",
        "    \"Do not mix GROUP BY with DISTINCT ON. If aggregation is needed (e.g., pairing BP), use GROUP BY + MAX(CASE...).\\n\"\n",
        "    \"Important: medication_requests has no rxnorm_code (use med_name only). Encounters has no location.\\n\"\n",
        "    \"If the question mentions 'blood pressure' or 'BP', return only systolic (8480-6) and diastolic (8462-4) results and prefer paired rows grouped by effective_datetime.\\n\"\n",
        "    \"\\n\"\n",
        "    \"Schema hints:\\n\"\n",
        "    \"  conditions(display, code, onset_datetime, abatement_datetime, encounter_id, patient_id, condition_id)\\n\"\n",
        "    \"  observations(display, loinc_code, value_num, value_unit, effective_datetime, encounter_id, patient_id, observation_id)\\n\"\n",
        "    \"  medication_requests(med_name, dose, route, start_datetime, end_datetime, refills, encounter_id, patient_id, med_request_id)\\n\"\n",
        "    \"  encounters(start_datetime, end_datetime, reason_text, class, encounter_id, patient_id)\\n\"\n",
        "    \"  procedures(display, code, performed_datetime, encounter_id, patient_id, procedure_id)\\n\"\n",
        "    \"Output only the raw SQL, no markdown fences.\"\n",
        ")\n",
        "\n",
        "def get_few_shots(query: str, k: int = 3):\n",
        "    # uses your already-loaded FAISS vector store: `vs`\n",
        "    docs_scores = vs.similarity_search_with_score(query, k=k)\n",
        "    examples = [{\"question\": d.page_content, \"sql\": (d.metadata or {}).get(\"sql\",\"\")} for d, _ in docs_scores]\n",
        "    return examples\n",
        "\n",
        "def format_examples(examples):\n",
        "    return \"\\n\".join([f\"Question: {ex['question']}\\nSQL:\\n{ex['sql']}\\n\" for ex in examples])\n",
        "\n",
        "def build_prompt(user_question: str, k: int = 3) -> str:\n",
        "    examples = get_few_shots(user_question, k=k)\n",
        "    return f\"{PREFIX}\\n{format_examples(examples)}\\nQuestion: {user_question}\\nSQL:\"\n"
      ],
      "metadata": {
        "id": "fnUPJ6gRVpDN"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 5) SQL generation + a tiny safety check ---\n",
        "import re\n",
        "\n",
        "SELECT_ONLY = re.compile(r\"^\\s*select\\b\", re.IGNORECASE | re.DOTALL)\n",
        "\n",
        "def clean_sql(text: str) -> str:\n",
        "    s = text.strip()\n",
        "\n",
        "    # strip a leading \"SQL:\" line if present\n",
        "    if s.lower().startswith(\"sql:\"):\n",
        "        s = s[4:].strip()\n",
        "\n",
        "    # strip fenced code blocks like ```sql ... ``` or ``` ... ```\n",
        "    m = re.match(r\"^```(?:\\s*sql)?\\s*([\\s\\S]*?)\\s*```$\", s, flags=re.IGNORECASE)\n",
        "    if m:\n",
        "        s = m.group(1).strip()\n",
        "\n",
        "    # strip stray backticks if the model emitted them oddly\n",
        "    if s.startswith(\"```\") and \"```\" in s[3:]:\n",
        "        s = s.split(\"```\", 1)[1].rsplit(\"```\", 1)[0].strip()\n",
        "\n",
        "    # remove BOM or weird invisibles\n",
        "    s = s.replace(\"\\ufeff\", \"\").replace(\"\\u200b\", \"\").strip()\n",
        "    return s\n",
        "\n",
        "def is_safe_select(text: str) -> bool:\n",
        "    sql = clean_sql(text)\n",
        "\n",
        "    # (optional) reject multiple statements (allow a single trailing semicolon)\n",
        "    trimmed = sql.strip()\n",
        "    if \";\" in trimmed[:-1]:  # semicolon before the last char\n",
        "        return False\n",
        "\n",
        "    if not SELECT_ONLY.match(trimmed):\n",
        "        return False\n",
        "\n",
        "    banned = (\" insert \", \" update \", \" delete \", \" drop \", \" alter \",\n",
        "              \" create \", \" grant \", \" revoke \", \" truncate \")\n",
        "    low = f\" {trimmed.lower()} \"  # pad with spaces to avoid substring accidents\n",
        "    return not any(b in low for b in banned)\n",
        "\n",
        "def generate_sql(user_question: str, k: int = 3, max_tokens: int = 400):\n",
        "    prompt = build_prompt(user_question, k=k)\n",
        "    resp = client.chat.completions.create(\n",
        "        model=LLM_MODEL,\n",
        "        temperature=0,\n",
        "        messages=[\n",
        "            {\"role\":\"system\",\"content\":\"You are a precise SQL generator for a patient portal.\"},\n",
        "            {\"role\":\"user\",\"content\": prompt}\n",
        "        ],\n",
        "        max_tokens=max_tokens,\n",
        "    )\n",
        "    sql = resp.choices[0].message.content.strip()\n",
        "    return sql\n",
        "\n",
        "# Demo\n",
        "demo_q = \"Which medications am I currently taking?\"\n",
        "sql = generate_sql(demo_q, k=3)\n",
        "print(sql, \"\\n\\nSAFE:\", is_safe_select(sql))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wX2WFQjTWF__",
        "outputId": "f4d3be7e-a80e-4022-ce7c-f8b73d0df3be"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SELECT DISTINCT ON (mr.patient_id, mr.med_name)\n",
            "  mr.patient_id,\n",
            "  mr.med_name AS medication,\n",
            "  mr.dose,\n",
            "  mr.route,\n",
            "  mr.start_datetime,\n",
            "  mr.end_datetime,\n",
            "  mr.refills\n",
            "FROM medication_requests mr\n",
            "WHERE mr.patient_id = :patient_id\n",
            "  AND (mr.end_datetime IS NULL OR mr.end_datetime >= NOW())\n",
            "ORDER BY mr.patient_id,\n",
            "         mr.med_name,\n",
            "         COALESCE(mr.end_datetime, mr.start_datetime) DESC NULLS LAST; \n",
            "\n",
            "SAFE: True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load PostgreSQL EHR FHIR Database"
      ],
      "metadata": {
        "id": "NLUdvFaHW5ze"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vwDFdoEaYhPG"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!apt-get -y update\n",
        "!apt-get -y install postgresql postgresql-contrib\n",
        "\n",
        "!service postgresql start\n",
        "!sudo -u postgres psql -c \"ALTER USER postgres PASSWORD 'postgres';\"\n",
        "!sudo -u postgres createdb synthea_ehr\n",
        "\n",
        "!echo \"PostgreSQL installed, service started, user password set to 'postgres', and DB 'synthea_ehr' created.\"\n"
      ],
      "metadata": {
        "id": "jukSLteKwC_9"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import subprocess\n",
        "import os\n",
        "\n",
        "# Database connection details\n",
        "DB_NAME = \"synthea_ehr\"\n",
        "DB_USER = \"postgres\"\n",
        "DB_PASSWORD = \"postgres\"\n",
        "DB_HOST = \"localhost\"\n",
        "\n",
        "# Path on Google Drive to the backup file\n",
        "BACKUP_PATH = DEV_PATH + \"/synthea_ehr_backup.sql\"\n",
        "\n",
        "def restore_database():\n",
        "    \"\"\"Restores the synthea_ehr database from a file on Google Drive.\"\"\"\n",
        "    try:\n",
        "        print(\"Starting database restore...\")\n",
        "\n",
        "        # First, drop and re-create the database to ensure a clean state\n",
        "        print(\"Dropping and re-creating the database for a clean restore...\")\n",
        "        env = os.environ.copy()\n",
        "        env['PGPASSWORD'] = DB_PASSWORD\n",
        "\n",
        "        # Command to drop the database\n",
        "        drop_command = [\n",
        "            'dropdb',\n",
        "            '--host', DB_HOST,\n",
        "            '--username', DB_USER,\n",
        "            DB_NAME\n",
        "        ]\n",
        "        # This will fail if the DB doesn't exist, so we don't check for errors\n",
        "        subprocess.run(drop_command, env=env, check=False, capture_output=True, text=True)\n",
        "\n",
        "        # Command to create the database\n",
        "        create_command = [\n",
        "            'createdb',\n",
        "            '--host', DB_HOST,\n",
        "            '--username', DB_USER,\n",
        "            DB_NAME\n",
        "        ]\n",
        "        subprocess.run(create_command, env=env, check=True, capture_output=True, text=True)\n",
        "        print(\"Database re-created successfully.\")\n",
        "\n",
        "        # Use subprocess to run the psql command to restore the backup\n",
        "        command = [\n",
        "            'psql',\n",
        "            '--host', DB_HOST,\n",
        "            '--username', DB_USER,\n",
        "            '--dbname', DB_NAME,\n",
        "            '--file', BACKUP_PATH\n",
        "        ]\n",
        "\n",
        "        process = subprocess.run(command, env=env, check=True, capture_output=True, text=True)\n",
        "        print(\"Database restore successful!\")\n",
        "\n",
        "    except FileNotFoundError:\n",
        "        print(\"Error: psql or dropdb/createdb commands not found. Please ensure PostgreSQL client tools are installed.\")\n",
        "        print(\"You can try running: !apt-get update && !apt-get install -y postgresql-client\")\n",
        "    except subprocess.CalledProcessError as e:\n",
        "        print(\"Error during restore process.\")\n",
        "        print(f\"Subprocess returned non-zero exit code: {e.returncode}\")\n",
        "        print(f\"STDOUT:\\n{e.stdout}\")\n",
        "        print(f\"STDERR:\\n{e.stderr}\")\n",
        "    except Exception as e:\n",
        "        print(f\"An unexpected error occurred: {e}\")\n",
        "\n",
        "restore_database()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OXTgwQ84YuzG",
        "outputId": "98df6bc5-374c-4a41-95a0-231a0c50972e"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting database restore...\n",
            "Dropping and re-creating the database for a clean restore...\n",
            "Database re-created successfully.\n",
            "Database restore successful!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# If needed once per runtime:\n",
        "# !pip -q install psycopg2-binary\n",
        "\n",
        "import re\n",
        "import psycopg2\n",
        "import psycopg2.extras\n",
        "\n",
        "# Uses your existing globals:\n",
        "# DB_NAME = \"synthea_ehr\"\n",
        "# DB_USER = \"postgres\"\n",
        "# DB_PASSWORD = \"postgres\"\n",
        "# DB_HOST = \"localhost\"\n",
        "\n",
        "# --- helpers ---\n",
        "_SELECT_ONLY = re.compile(r\"^\\s*select\\b\", re.IGNORECASE | re.DOTALL)\n",
        "_BANNED = (\" insert \", \" update \", \" delete \", \" drop \", \" alter \",\n",
        "           \" create \", \" grant \", \" revoke \", \" truncate \", \" copy \", \" do \")\n",
        "\n",
        "# match :name (not preceded by another :)\n",
        "_PARAM = re.compile(r'(?<!:):([a-zA-Z_]\\w*)')\n",
        "\n",
        "def _clean_sql(text: str) -> str:\n",
        "    \"\"\"Remove code fences / labels and invisible chars.\"\"\"\n",
        "    s = (text or \"\").strip()\n",
        "    if s.lower().startswith(\"sql:\"):\n",
        "        s = s[4:].strip()\n",
        "    m = re.match(r\"^```(?:\\s*sql)?\\s*([\\s\\S]*?)\\s*```$\", s, flags=re.IGNORECASE)\n",
        "    if m:\n",
        "        s = m.group(1).strip()\n",
        "    return s.replace(\"\\ufeff\",\"\").replace(\"\\u200b\",\"\").strip()\n",
        "\n",
        "def _is_safe_select(sql: str) -> bool:\n",
        "    \"\"\"Single SELECT only; no DDL/DML keywords; no mid-string semicolons.\"\"\"\n",
        "    s = sql.strip()\n",
        "    if \";\" in s[:-1]:  # allow a single trailing semicolon only\n",
        "        return False\n",
        "    if not _SELECT_ONLY.match(s):\n",
        "        return False\n",
        "    low = f\" {s.lower()} \"\n",
        "    return not any(b in low for b in _BANNED)\n",
        "\n",
        "def _to_psycopg2_named(sql: str) -> str:\n",
        "    \"\"\"Convert :name placeholders to %(name)s for psycopg2.\"\"\"\n",
        "    return _PARAM.sub(r\"%(\\1)s\", sql)\n",
        "\n",
        "# --- main function ---\n",
        "def execute_sql(sql: str, params: dict = None, timeout_ms: int = 5000):\n",
        "    \"\"\"\n",
        "    Execute a single SELECT query safely and return rows as a list of dicts.\n",
        "\n",
        "    Args:\n",
        "      sql: SQL string (can use :param style placeholders, e.g., :patient_id)\n",
        "      params: dict of parameters if placeholders are used (optional)\n",
        "      timeout_ms: statement timeout in milliseconds (default 5000)\n",
        "\n",
        "    Returns:\n",
        "      List[Dict]: each row as a dict\n",
        "    \"\"\"\n",
        "    raw = _clean_sql(sql)\n",
        "    if not _is_safe_select(raw):\n",
        "        raise ValueError(\"Blocked: SQL must be a single SELECT without DDL/DML.\")\n",
        "\n",
        "    q = _to_psycopg2_named(raw)\n",
        "    params = params or {}\n",
        "\n",
        "    conn = psycopg2.connect(\n",
        "        dbname=DB_NAME,\n",
        "        user=DB_USER,\n",
        "        password=DB_PASSWORD,\n",
        "        host=DB_HOST,\n",
        "        port=5432,\n",
        "        connect_timeout=5,\n",
        "        options=f\"-c statement_timeout={timeout_ms}\"\n",
        "    )\n",
        "    try:\n",
        "        with conn.cursor(cursor_factory=psycopg2.extras.RealDictCursor) as cur:\n",
        "            cur.execute(q, params)\n",
        "            return [dict(r) for r in cur.fetchall()]\n",
        "    finally:\n",
        "        conn.close()\n"
      ],
      "metadata": {
        "id": "bRFg7hQKaTKm"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Test\n",
        "\n",
        "# Simple\n",
        "rows = execute_sql(\"SELECT COUNT(*) AS n FROM patients;\")\n",
        "print(rows)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3x_1OJZSaVAU",
        "outputId": "634051a3-55cf-4628-baff-f8fee46b3ff5"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[{'n': 111}]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rows = execute_sql(\"select patient_id from patients;\")\n",
        "print(rows[:3])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S-ncoErHam-5",
        "outputId": "e4fd5dcb-69b6-4c1c-dc80-be6714fc35e4"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[{'patient_id': '8c8e1c9a-b310-43c6-33a7-ad11bad21c40'}, {'patient_id': '782001bc-f712-50ae-04f5-9a488f3ef4aa'}, {'patient_id': '80e7f50a-3e99-d5ac-cf97-f8a4b4f9e6c7'}]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "execute_sql(\"\"\"\n",
        "SELECT column_name\n",
        "FROM information_schema.columns\n",
        "WHERE table_schema='public' AND table_name='encounters'\n",
        "ORDER BY 1;\n",
        "\"\"\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-dOIOq8ubNuO",
        "outputId": "2ce591b2-db9b-4242-b1cf-2d473199cfd2"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'column_name': 'class'},\n",
              " {'column_name': 'encounter_id'},\n",
              " {'column_name': 'end_datetime'},\n",
              " {'column_name': 'patient_id'},\n",
              " {'column_name': 'reason_text'},\n",
              " {'column_name': 'start_datetime'}]"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "execute_sql(\"\"\"\n",
        "SELECT table_name, column_name\n",
        "FROM information_schema.columns\n",
        "WHERE table_schema='public'\n",
        "ORDER BY 1;\n",
        "\"\"\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3qqD8lkvg1cD",
        "outputId": "661435a1-c438-40ac-c486-0d234ec1d05b"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'table_name': 'conditions', 'column_name': 'onset_datetime'},\n",
              " {'table_name': 'conditions', 'column_name': 'patient_id'},\n",
              " {'table_name': 'conditions', 'column_name': 'encounter_id'},\n",
              " {'table_name': 'conditions', 'column_name': 'code'},\n",
              " {'table_name': 'conditions', 'column_name': 'display'},\n",
              " {'table_name': 'conditions', 'column_name': 'condition_id'},\n",
              " {'table_name': 'conditions', 'column_name': 'abatement_datetime'},\n",
              " {'table_name': 'encounters', 'column_name': 'reason_text'},\n",
              " {'table_name': 'encounters', 'column_name': 'start_datetime'},\n",
              " {'table_name': 'encounters', 'column_name': 'end_datetime'},\n",
              " {'table_name': 'encounters', 'column_name': 'encounter_id'},\n",
              " {'table_name': 'encounters', 'column_name': 'patient_id'},\n",
              " {'table_name': 'encounters', 'column_name': 'class'},\n",
              " {'table_name': 'immunizations', 'column_name': 'base_cost'},\n",
              " {'table_name': 'immunizations', 'column_name': 'code'},\n",
              " {'table_name': 'immunizations', 'column_name': 'date'},\n",
              " {'table_name': 'immunizations', 'column_name': 'encounter_id'},\n",
              " {'table_name': 'immunizations', 'column_name': 'display'},\n",
              " {'table_name': 'immunizations', 'column_name': 'patient_id'},\n",
              " {'table_name': 'medication_requests', 'column_name': 'refills'},\n",
              " {'table_name': 'medication_requests', 'column_name': 'dose'},\n",
              " {'table_name': 'medication_requests', 'column_name': 'patient_id'},\n",
              " {'table_name': 'medication_requests', 'column_name': 'med_request_id'},\n",
              " {'table_name': 'medication_requests', 'column_name': 'med_name'},\n",
              " {'table_name': 'medication_requests', 'column_name': 'encounter_id'},\n",
              " {'table_name': 'medication_requests', 'column_name': 'end_datetime'},\n",
              " {'table_name': 'medication_requests', 'column_name': 'start_datetime'},\n",
              " {'table_name': 'medication_requests', 'column_name': 'route'},\n",
              " {'table_name': 'observations', 'column_name': 'observation_id'},\n",
              " {'table_name': 'observations', 'column_name': 'value_num'},\n",
              " {'table_name': 'observations', 'column_name': 'effective_datetime'},\n",
              " {'table_name': 'observations', 'column_name': 'patient_id'},\n",
              " {'table_name': 'observations', 'column_name': 'encounter_id'},\n",
              " {'table_name': 'observations', 'column_name': 'loinc_code'},\n",
              " {'table_name': 'observations', 'column_name': 'display'},\n",
              " {'table_name': 'observations', 'column_name': 'value_unit'},\n",
              " {'table_name': 'patients', 'column_name': 'sex'},\n",
              " {'table_name': 'patients', 'column_name': 'race'},\n",
              " {'table_name': 'patients', 'column_name': 'patient_id'},\n",
              " {'table_name': 'patients', 'column_name': 'birth_date'},\n",
              " {'table_name': 'patients', 'column_name': 'ethnicity'},\n",
              " {'table_name': 'procedures', 'column_name': 'patient_id'},\n",
              " {'table_name': 'procedures', 'column_name': 'performed_datetime'},\n",
              " {'table_name': 'procedures', 'column_name': 'procedure_id'},\n",
              " {'table_name': 'procedures', 'column_name': 'display'},\n",
              " {'table_name': 'procedures', 'column_name': 'code'},\n",
              " {'table_name': 'procedures', 'column_name': 'encounter_id'}]"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# With parameter (your canonical pattern)\n",
        "q = \"\"\"\n",
        "SELECT DISTINCT ON (mr.patient_id, mr.med_name)\n",
        "  mr.patient_id,\n",
        "  mr.med_name AS medication,\n",
        "  mr.dose,\n",
        "  mr.route,\n",
        "  mr.start_datetime,\n",
        "  mr.end_datetime,\n",
        "  mr.refills\n",
        "FROM medication_requests mr\n",
        "WHERE mr.patient_id = :patient_id\n",
        "  AND (mr.end_datetime IS NULL OR mr.end_datetime >= NOW())\n",
        "ORDER BY mr.patient_id,\n",
        "         mr.med_name,\n",
        "         COALESCE(mr.end_datetime, mr.start_datetime) DESC NULLS LAST;\n",
        "\n",
        "\"\"\"\n",
        "rows = execute_sql(q, {\"patient_id\": '8c8e1c9a-b310-43c6-33a7-ad11bad21c40'})\n",
        "print(rows[:3])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4xvKbyXjag0c",
        "outputId": "ae2a5451-76ac-4951-88d4-7e7524da42eb"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[{'patient_id': '8c8e1c9a-b310-43c6-33a7-ad11bad21c40', 'medication': 'Acetaminophen 325 MG Oral Tablet', 'dose': None, 'route': None, 'start_datetime': None, 'end_datetime': None, 'refills': None}, {'patient_id': '8c8e1c9a-b310-43c6-33a7-ad11bad21c40', 'medication': 'Naproxen sodium 220 MG Oral Tablet', 'dose': None, 'route': None, 'start_datetime': None, 'end_datetime': None, 'refills': None}]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tie LLM output to return results from PostGre SQL database"
      ],
      "metadata": {
        "id": "CgHSfGX9bbV7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def answer_patient_question(user_question: str, patient_id: str, k: int = 3, max_tokens: int = 400 ):\n",
        "    sql = generate_sql(user_question, k=k, max_tokens=max_tokens)\n",
        "    #print(\"answer_patient_question: Generated SQL:\\n\", sql, \"\\n\")\n",
        "    rows = execute_sql(sql, {\"patient_id\": patient_id})\n",
        "    #print(\"answer_patient_question: Executed SQL returned rows:\\n\", len(rows), \"\\n\")\n",
        "    return sql, rows\n"
      ],
      "metadata": {
        "id": "PEqedRenc0z4"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "execute_sql(\"select p.patient_id from patients p\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZZKBQEmDmrjx",
        "outputId": "1f6d8766-6215-4fc5-9349-85bddddec6e4"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'patient_id': '8c8e1c9a-b310-43c6-33a7-ad11bad21c40'},\n",
              " {'patient_id': '782001bc-f712-50ae-04f5-9a488f3ef4aa'},\n",
              " {'patient_id': '80e7f50a-3e99-d5ac-cf97-f8a4b4f9e6c7'},\n",
              " {'patient_id': 'edc17058-55fb-08c7-12df-ece93a402e50'},\n",
              " {'patient_id': '9f9dbdcb-23a1-82cc-b7bc-e0e420a95bd1'},\n",
              " {'patient_id': 'be874504-c868-ebfd-9a77-df6b1e5ff6cc'},\n",
              " {'patient_id': '30e48e16-2df7-207e-7a3d-1650ef0c1ed8'},\n",
              " {'patient_id': '57b21dea-ff00-6c3e-92d9-91c7627f53b2'},\n",
              " {'patient_id': 'a3d34c1f-5421-e078-38ec-1498a5941dbe'},\n",
              " {'patient_id': 'e83fe1b3-f94f-5591-f851-1da300e24e99'},\n",
              " {'patient_id': 'e6705c33-7349-8b12-484d-3b1f93227178'},\n",
              " {'patient_id': '2da86d63-34ae-b887-ddff-8f6f1e6990f1'},\n",
              " {'patient_id': '04181caa-fcc1-c6c8-743e-a903eff368de'},\n",
              " {'patient_id': '20802592-1c31-7339-4c4c-2fe648e1a716'},\n",
              " {'patient_id': '406e8bad-81b5-7624-5b8a-4aeeb74028f5'},\n",
              " {'patient_id': 'a331b5bc-cbea-a205-a8bf-dbf3255ef36a'},\n",
              " {'patient_id': '641efcda-7397-4172-c6ac-8231342fa53e'},\n",
              " {'patient_id': 'e64918a6-528c-b49e-dff2-3cbe33266342'},\n",
              " {'patient_id': '9c6ef4a8-79e8-92c4-2279-a0666694419b'},\n",
              " {'patient_id': '7757f538-bffe-a8bf-0efb-8363354aab87'},\n",
              " {'patient_id': '5a0fd7a2-6bfd-af1e-7bb6-2060136302c3'},\n",
              " {'patient_id': 'eeae0d25-5865-76b4-8ad7-9526bcf3a94d'},\n",
              " {'patient_id': '5dbd017f-d447-9546-8610-8f7bdaa77789'},\n",
              " {'patient_id': '6754b3bf-f5ac-f359-fef6-87cf4b8508ab'},\n",
              " {'patient_id': '0098f2a9-2f4d-4209-778d-cb3426d85987'},\n",
              " {'patient_id': '3270397c-dfa3-6cea-f2ec-be21ade6c52c'},\n",
              " {'patient_id': '3477fa4e-a09a-e779-5d56-eeb00dee758b'},\n",
              " {'patient_id': '74a4cdcf-7cc0-7658-e1e0-cd1182d5f205'},\n",
              " {'patient_id': '0c76b28e-5685-0754-12d1-b1a6b79866f7'},\n",
              " {'patient_id': 'f4e9b2c8-9db5-5597-a6a7-1215a638c1e2'},\n",
              " {'patient_id': '8f87d617-a91b-29e0-e155-96a5d71de419'},\n",
              " {'patient_id': '97a046ab-d147-2707-d4cd-cba26c5360ad'},\n",
              " {'patient_id': '8dacd3c2-9e71-7d5d-02aa-7ad9541a0ab9'},\n",
              " {'patient_id': '15c6645a-8f7b-df42-95ec-8b49bda12c10'},\n",
              " {'patient_id': 'c8114bff-6bab-8353-597d-4f155f5f1c3e'},\n",
              " {'patient_id': '1c1ab155-7314-095d-1641-06efd2cd0873'},\n",
              " {'patient_id': 'f380d818-b685-618e-22dc-b2db2fe0a6c0'},\n",
              " {'patient_id': 'c3dae8db-25ee-c40b-c605-600fad411d34'},\n",
              " {'patient_id': '0db7560a-db72-0cef-c59c-1fd6762bc50d'},\n",
              " {'patient_id': '349720c1-0627-e77a-1619-bb11b1530e96'},\n",
              " {'patient_id': '37895f0e-877f-7ea7-aa1b-0b69fcd11385'},\n",
              " {'patient_id': 'ef2eaed0-b056-2a9f-7ccb-07a9c9fdabd5'},\n",
              " {'patient_id': '119e46a1-9323-916b-4152-e0daedb48f23'},\n",
              " {'patient_id': 'faec5a04-6c56-4296-9fec-4e218e627a32'},\n",
              " {'patient_id': '7cad1f7c-cf61-fd24-254f-d02265160c0a'},\n",
              " {'patient_id': '3f7873ab-0f61-be0c-9af8-f246eec6223a'},\n",
              " {'patient_id': '3ac8c3a5-3c16-699f-537b-e7816347104b'},\n",
              " {'patient_id': '103b63c9-9ef8-6d25-771e-2fba661489a1'},\n",
              " {'patient_id': '13ac6eee-8cf1-e597-1c91-453c8f069a3c'},\n",
              " {'patient_id': '7785daad-accb-cb33-7d8f-2faebf8eb639'},\n",
              " {'patient_id': 'fc3e2c0f-6809-7e7b-4ad8-769a732bf13a'},\n",
              " {'patient_id': '750eda4e-3f12-c701-869e-1d392387dfa0'},\n",
              " {'patient_id': '782ada1b-32a4-888a-8812-d8de70d6e5d0'},\n",
              " {'patient_id': '2e2eb927-efd5-bbd4-297d-99071243a8cb'},\n",
              " {'patient_id': 'add41d13-8e70-e327-4367-8d945e20f27b'},\n",
              " {'patient_id': 'd423f0d1-e7ed-d47e-af4f-20cfd996ac67'},\n",
              " {'patient_id': '033cccaf-bc92-3ddd-b64c-9ea45268a971'},\n",
              " {'patient_id': 'add095a2-64e5-aae2-11d2-9be2f89ff843'},\n",
              " {'patient_id': '006c29d1-d868-3a9e-ceab-31f23e398f45'},\n",
              " {'patient_id': '1f0ca842-8c2d-a943-c047-dafce690f5a2'},\n",
              " {'patient_id': '7ddb0322-da41-c9d3-2018-4581109426b2'},\n",
              " {'patient_id': '4faedf9f-2c0e-9800-943a-0930bd08c4c8'},\n",
              " {'patient_id': '80cca49f-29f9-d04f-851d-84b95f863793'},\n",
              " {'patient_id': '583c0740-39e1-9e33-f9d6-4fdb2b815669'},\n",
              " {'patient_id': 'b9bacf2f-7027-2e05-fa5b-19167071fdde'},\n",
              " {'patient_id': '3c763653-7fd3-af8a-e65f-79d5bde98d3a'},\n",
              " {'patient_id': 'ae05f1fa-7913-f7bc-41bd-2dc8827555e7'},\n",
              " {'patient_id': 'e1c6b5c4-34b7-7296-56ed-4c634e93deb9'},\n",
              " {'patient_id': '9cbd97ef-2209-9b1c-b6f7-a23a6c081740'},\n",
              " {'patient_id': '0e5401fd-b241-3c84-066e-2b88e5ddafc7'},\n",
              " {'patient_id': '575cac8f-bed1-32da-30a6-3a516a78500d'},\n",
              " {'patient_id': '3de203ff-a5b9-e99a-c705-3927503e2abf'},\n",
              " {'patient_id': 'fd7387f3-3465-7a34-6778-25aac38a13c2'},\n",
              " {'patient_id': '02cb6ae2-d3fd-e497-7077-77cdbeb5f0a1'},\n",
              " {'patient_id': '1e9713a5-742f-aca0-cf95-446338fdc57f'},\n",
              " {'patient_id': '55bc1034-ecf9-d005-5b9e-eac706fe541f'},\n",
              " {'patient_id': 'b5193ef4-ab73-ddd3-e7dd-d8168b33e7f6'},\n",
              " {'patient_id': 'c420eb5d-97eb-59b6-b247-0ba188408db5'},\n",
              " {'patient_id': '1754bc7d-28cd-4933-fc72-3d9a0d77cf54'},\n",
              " {'patient_id': 'b61886a1-b76f-4ecf-b37a-29d0c6aefc26'},\n",
              " {'patient_id': '0851b7fb-87a8-3edc-1e11-8dcb03824dde'},\n",
              " {'patient_id': '25f30c19-e98a-85ea-6de8-f976388d4678'},\n",
              " {'patient_id': '6da68959-d157-b9a3-48bc-1454e5517d6a'},\n",
              " {'patient_id': '0a1bd9a2-fc21-7ad3-3d85-cf31b68eec28'},\n",
              " {'patient_id': 'bd6e7acc-7c87-7f0a-5d15-959cf11e22da'},\n",
              " {'patient_id': '31014896-9c27-ae1a-71db-319df60ac5d3'},\n",
              " {'patient_id': '49424eb4-e2ba-40b5-0e2b-2c2d742cce4b'},\n",
              " {'patient_id': '48f06a5e-0d20-3fe6-f5ea-b45bc79e90db'},\n",
              " {'patient_id': '787f9e8e-d3a4-0407-55d1-01a3414fceaf'},\n",
              " {'patient_id': '5c68f376-dd2c-1133-a9cf-f023a5d99078'},\n",
              " {'patient_id': 'e5ed5bc3-51e1-a9a7-01fb-f66b8ac4045d'},\n",
              " {'patient_id': 'cae42a0d-c36c-8af1-8277-7c9abd011778'},\n",
              " {'patient_id': '155b0e07-d5a9-cc0c-e01a-a982c5d9a8d6'},\n",
              " {'patient_id': '04300771-e00c-e414-830a-66f7ef3584da'},\n",
              " {'patient_id': '45e1243b-470c-efa8-8ce9-f0d50485a846'},\n",
              " {'patient_id': '9f867ec4-9f3a-35af-4bb6-e2c18a603c72'},\n",
              " {'patient_id': 'b8ded152-e326-5833-f747-bf9b35c60a76'},\n",
              " {'patient_id': '70775c58-59fb-a3db-9858-1d427567c195'},\n",
              " {'patient_id': 'b427e4ea-3a48-207a-bf7d-710f0b574091'},\n",
              " {'patient_id': '0fca905f-391c-08d3-4b93-b53f69b9da53'},\n",
              " {'patient_id': '5fda1015-d0a5-e32d-d0b8-4662e6ce6c2b'},\n",
              " {'patient_id': '43e4a5fe-add4-5581-d0ef-80764c313418'},\n",
              " {'patient_id': '28f107b5-e973-ece3-b762-c2dbd9a01ba8'},\n",
              " {'patient_id': '6f808eef-a811-11eb-3fcb-1ed910d79c4b'},\n",
              " {'patient_id': '77dfae18-8c8c-0ec2-050c-dd93f3ea1cc2'},\n",
              " {'patient_id': '5f9bfe93-062d-ca4b-5389-f8cac604a7e3'},\n",
              " {'patient_id': '2bc26ad6-ad32-0bb0-f964-0fe271fdf054'},\n",
              " {'patient_id': 'f49221bb-20fb-45cb-9345-09b6a83ae9de'},\n",
              " {'patient_id': '9ad4a69b-02de-4aeb-2262-76745583a8ac'},\n",
              " {'patient_id': '72b7a6b1-b196-7ba5-eb82-1e9b0f75b7bd'},\n",
              " {'patient_id': '1a9873c2-1d93-e9d6-4e36-77fdb07fbcb2'}]"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sql = (\n",
        "    \"SELECT e.patient_id, e.start_datetime, e.end_datetime, \"\n",
        "    \"e.class AS encounter_class, e.reason_text AS reason \"\n",
        "    \"FROM encounters e \"\n",
        "    \"WHERE e.reason_text IS NOT NULL;\"\n",
        ")\n",
        "execute_sql(sql)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bz0ABMyonvZk",
        "outputId": "9ab4804b-bc54-43c9-a5da-7c8695247cd4"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[]"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "cSjjFKTc_fPr"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "patient_id = '0fca905f-391c-08d3-4b93-b53f69b9da53'\n",
        "user_q = \"List all my vital signs\"\n",
        "\n",
        "sql, rows = answer_patient_question(user_q, patient_id, k=5, max_tokens=1000)\n",
        "print(\"Generated SQL:\\n\", sql, \"\\n\")\n",
        "print(\"Rows:\", len(rows))\n",
        "if rows:\n",
        "    display(pd.DataFrame(rows).head(10))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 733
        },
        "id": "YpEOmc0tc3dZ",
        "outputId": "04ee61b9-3cb0-44d6-c64f-57e0ad2016a6"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated SQL:\n",
            " SELECT\n",
            "  o.patient_id,\n",
            "  COALESCE(o.display, o.loinc_code) AS vital_name,\n",
            "  o.value_num AS value,\n",
            "  o.value_unit AS unit,\n",
            "  o.effective_datetime\n",
            "FROM observations AS o\n",
            "WHERE o.patient_id = :patient_id\n",
            "  AND (\n",
            "    o.loinc_code IN ('8480-6','8462-4','8867-4','9279-1','8310-5','59408-5','29463-7','39156-5','8302-2')\n",
            "    OR LOWER(o.display) IN (\n",
            "      'systolic blood pressure','diastolic blood pressure',\n",
            "      'heart rate','respiratory rate','body temperature',\n",
            "      'oxygen saturation','body weight','bmi','body mass index','body height'\n",
            "    )\n",
            "  )\n",
            "ORDER BY\n",
            "  o.effective_datetime DESC NULLS LAST,\n",
            "  COALESCE(o.display, o.loinc_code); \n",
            "\n",
            "Rows: 56\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "                             patient_id                     vital_name  value  \\\n",
              "0  0fca905f-391c-08d3-4b93-b53f69b9da53                    Body Height  183.4   \n",
              "1  0fca905f-391c-08d3-4b93-b53f69b9da53  Body mass index (BMI) [Ratio]  28.35   \n",
              "2  0fca905f-391c-08d3-4b93-b53f69b9da53                    Body Weight   95.4   \n",
              "3  0fca905f-391c-08d3-4b93-b53f69b9da53                     Heart rate     69   \n",
              "4  0fca905f-391c-08d3-4b93-b53f69b9da53               Respiratory rate     14   \n",
              "5  0fca905f-391c-08d3-4b93-b53f69b9da53                    Body Height  183.4   \n",
              "6  0fca905f-391c-08d3-4b93-b53f69b9da53  Body mass index (BMI) [Ratio]  28.26   \n",
              "7  0fca905f-391c-08d3-4b93-b53f69b9da53                    Body Weight   95.1   \n",
              "8  0fca905f-391c-08d3-4b93-b53f69b9da53                     Heart rate     83   \n",
              "9  0fca905f-391c-08d3-4b93-b53f69b9da53               Respiratory rate     15   \n",
              "\n",
              "    unit        effective_datetime  \n",
              "0     cm 2025-04-21 14:19:34+00:00  \n",
              "1  kg/m2 2025-04-21 14:19:34+00:00  \n",
              "2     kg 2025-04-21 14:19:34+00:00  \n",
              "3   /min 2025-04-21 14:19:34+00:00  \n",
              "4   /min 2025-04-21 14:19:34+00:00  \n",
              "5     cm 2024-04-15 14:19:34+00:00  \n",
              "6  kg/m2 2024-04-15 14:19:34+00:00  \n",
              "7     kg 2024-04-15 14:19:34+00:00  \n",
              "8   /min 2024-04-15 14:19:34+00:00  \n",
              "9   /min 2024-04-15 14:19:34+00:00  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-227f968a-2227-435d-8e84-af9c90655c64\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>patient_id</th>\n",
              "      <th>vital_name</th>\n",
              "      <th>value</th>\n",
              "      <th>unit</th>\n",
              "      <th>effective_datetime</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0fca905f-391c-08d3-4b93-b53f69b9da53</td>\n",
              "      <td>Body Height</td>\n",
              "      <td>183.4</td>\n",
              "      <td>cm</td>\n",
              "      <td>2025-04-21 14:19:34+00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0fca905f-391c-08d3-4b93-b53f69b9da53</td>\n",
              "      <td>Body mass index (BMI) [Ratio]</td>\n",
              "      <td>28.35</td>\n",
              "      <td>kg/m2</td>\n",
              "      <td>2025-04-21 14:19:34+00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0fca905f-391c-08d3-4b93-b53f69b9da53</td>\n",
              "      <td>Body Weight</td>\n",
              "      <td>95.4</td>\n",
              "      <td>kg</td>\n",
              "      <td>2025-04-21 14:19:34+00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0fca905f-391c-08d3-4b93-b53f69b9da53</td>\n",
              "      <td>Heart rate</td>\n",
              "      <td>69</td>\n",
              "      <td>/min</td>\n",
              "      <td>2025-04-21 14:19:34+00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0fca905f-391c-08d3-4b93-b53f69b9da53</td>\n",
              "      <td>Respiratory rate</td>\n",
              "      <td>14</td>\n",
              "      <td>/min</td>\n",
              "      <td>2025-04-21 14:19:34+00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0fca905f-391c-08d3-4b93-b53f69b9da53</td>\n",
              "      <td>Body Height</td>\n",
              "      <td>183.4</td>\n",
              "      <td>cm</td>\n",
              "      <td>2024-04-15 14:19:34+00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0fca905f-391c-08d3-4b93-b53f69b9da53</td>\n",
              "      <td>Body mass index (BMI) [Ratio]</td>\n",
              "      <td>28.26</td>\n",
              "      <td>kg/m2</td>\n",
              "      <td>2024-04-15 14:19:34+00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>0fca905f-391c-08d3-4b93-b53f69b9da53</td>\n",
              "      <td>Body Weight</td>\n",
              "      <td>95.1</td>\n",
              "      <td>kg</td>\n",
              "      <td>2024-04-15 14:19:34+00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>0fca905f-391c-08d3-4b93-b53f69b9da53</td>\n",
              "      <td>Heart rate</td>\n",
              "      <td>83</td>\n",
              "      <td>/min</td>\n",
              "      <td>2024-04-15 14:19:34+00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>0fca905f-391c-08d3-4b93-b53f69b9da53</td>\n",
              "      <td>Respiratory rate</td>\n",
              "      <td>15</td>\n",
              "      <td>/min</td>\n",
              "      <td>2024-04-15 14:19:34+00:00</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-227f968a-2227-435d-8e84-af9c90655c64')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-227f968a-2227-435d-8e84-af9c90655c64 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-227f968a-2227-435d-8e84-af9c90655c64');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-081704e9-2c93-4beb-bd32-9312c4a0439b\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-081704e9-2c93-4beb-bd32-9312c4a0439b')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-081704e9-2c93-4beb-bd32-9312c4a0439b button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"    display(pd\",\n  \"rows\": 10,\n  \"fields\": [\n    {\n      \"column\": \"patient_id\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"0fca905f-391c-08d3-4b93-b53f69b9da53\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"vital_name\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"Body mass index (BMI) [Ratio]\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"value\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 9,\n        \"samples\": [\n          \"83\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"unit\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          \"kg/m2\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"effective_datetime\",\n      \"properties\": {\n        \"dtype\": \"date\",\n        \"min\": \"2024-04-15 14:19:34+00:00\",\n        \"max\": \"2025-04-21 14:19:34+00:00\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"2024-04-15 14:19:34+00:00\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Post data frame, LLM genberates a nice summary"
      ],
      "metadata": {
        "id": "S3-yc9S2wRHt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from openai import OpenAI\n",
        "import io\n",
        "\n",
        "client = OpenAI()  # assumes OPENAI_API_KEY is set\n"
      ],
      "metadata": {
        "id": "oPDicu1SwV6u"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def df_to_csv_for_llm(df: pd.DataFrame, max_rows: int = 200, null_marker: str = \"—\") -> tuple[str, bool]:\n",
        "    \"\"\"\n",
        "    Convert a DataFrame to CSV for the LLM.\n",
        "    - Truncates to max_rows to keep prompts small.\n",
        "    - Replaces NaNs with a visible marker (default \"—\").\n",
        "    Returns (csv_text, truncated_flag).\n",
        "    \"\"\"\n",
        "    truncated = False\n",
        "    if len(df) > max_rows:\n",
        "        df = df.head(max_rows).copy()\n",
        "        truncated = True\n",
        "\n",
        "    df = df.copy()\n",
        "    df = df.fillna(null_marker)\n",
        "\n",
        "    # keep column order stable\n",
        "    csv_buf = io.StringIO()\n",
        "    df.to_csv(csv_buf, index=False)\n",
        "    return csv_buf.getvalue(), truncated\n",
        "\n",
        "def summarize_df_with_llm(\n",
        "    df: pd.DataFrame,\n",
        "    patient_id: str,\n",
        "    model: str = \"gpt-4o-mini\",\n",
        "    max_rows: int = 200,\n",
        "    null_marker: str = \"—\",\n",
        "    max_tokens: int = 500\n",
        ") -> str:\n",
        "    \"\"\"\n",
        "    Ask the LLM to summarize a DataFrame.\n",
        "    - Includes all visible (non-missing) values in its reasoning context,\n",
        "      but the model will produce a concise natural-language summary (not a reprint of all rows).\n",
        "    \"\"\"\n",
        "    if df is None or df.empty:\n",
        "        return \"No data found for the requested query.\"\n",
        "\n",
        "    csv_text, truncated = df_to_csv_for_llm(df, max_rows=max_rows, null_marker=null_marker)\n",
        "    columns_csv = \",\".join(list(df.columns))\n",
        "\n",
        "    user_prompt = f\"\"\"\n",
        "You are a precise medical data summarizer. Use only the table below.\n",
        "- Do not invent values or fields.\n",
        "- Call out trends, counts, notable recency, and any obvious gaps (fields marked \"{null_marker}\").\n",
        "- Keep it concise (2–5 sentences).\n",
        "- If the table was truncated, say so and include how many rows were shown.\n",
        "\n",
        "Patient: {patient_id}\n",
        "Columns: {columns_csv}\n",
        "Rows shown: {min(len(df), max_rows)}{' (truncated)' if truncated else ''}\n",
        "\n",
        "CSV:\n",
        "{csv_text}\n",
        "\"\"\".strip()\n",
        "\n",
        "    resp = client.chat.completions.create(\n",
        "        model=model,\n",
        "        temperature=0,\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": \"You are a precise, conservative medical data summarizer.\"},\n",
        "            {\"role\": \"user\", \"content\": user_prompt},\n",
        "        ],\n",
        "        max_tokens=max_tokens,\n",
        "    )\n",
        "    return resp.choices[0].message.content.strip()\n"
      ],
      "metadata": {
        "id": "L_rq6oqnwXs3"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ##\n",
        "# patient_id = '0fca905f-391c-08d3-4b93-b53f69b9da53'\n",
        "# user_q = \"What has been my highest weight\"\n",
        "\n",
        "# sql, rows = answer_patient_question(user_q, patient_id, k=5, max_tokens=1000)\n",
        "# print(\"Generated SQL:\\n\", sql, \"\\n\")\n",
        "# print(\"Rows:\", len(rows))\n",
        "# # if rows:\n",
        "# #     display(pd.DataFrame(rows).head(10))\n",
        "# df = pd.DataFrame(rows)\n",
        "# display(df.head(10))\n",
        "# # 3) Summarize with the LLM\n",
        "# summary = summarize_df_with_llm(df, patient_id=\"<REAL-PATIENT-ID>\", model=LLM_MODEL)\n",
        "# print(summary)"
      ],
      "metadata": {
        "id": "-xLcfe6fwpg6"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Gradio UI"
      ],
      "metadata": {
        "id": "tq5PB1Pu4uHZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 0) Install Gradio (quiet)\n",
        "!pip -q install gradio\n",
        "\n",
        "# 1) Build a small adapter for the UI\n",
        "import pandas as pd\n",
        "import gradio as gr\n",
        "\n",
        "def medintellagent_ui(patient_id: str, user_question: str, k: int = 3, max_tokens: int = 600):\n",
        "    if not patient_id or not user_question:\n",
        "        return \"Please provide both patient_id and a question.\", pd.DataFrame(), \"—\"\n",
        "    try:\n",
        "        # Generate SQL + fetch rows\n",
        "        sql, rows = answer_patient_question(user_question, patient_id, k=k, max_tokens=max_tokens)\n",
        "        df = pd.DataFrame(rows)\n",
        "        if df.empty:\n",
        "            summary = \"No data found for this query (for this patient). Try another question or patient_id.\"\n",
        "        else:\n",
        "            summary = summarize_df_with_llm(df, patient_id=patient_id, model=LLM_MODEL)\n",
        "        return sql, df, summary\n",
        "    except Exception as e:\n",
        "        # Show errors cleanly in the UI (helpful during dev)\n",
        "        return f\"Error: {e}\", pd.DataFrame(), \"—\"\n",
        "\n",
        "# 2) Build the interface\n",
        "with gr.Blocks(css=\"footer {visibility: hidden}\") as demo:\n",
        "    gr.Markdown(\"# MedIntellAgent — MVP UI\")\n",
        "    gr.Markdown(\"Enter a **Patient ID** and **Question**. You’ll get the generated SQL, raw DB rows, and an LLM summary.\")\n",
        "\n",
        "    with gr.Row():\n",
        "        patient = gr.Textbox(label=\"Patient ID\", placeholder=\"e.g., 0fca905f-391c-08d3-4b93-b53f69b9da53\")\n",
        "    question = gr.Textbox(label=\"Patient Question\", lines=2,\n",
        "                          placeholder=\"e.g., Which medications am I currently taking?\")\n",
        "    with gr.Row():\n",
        "        k = gr.Slider(1, 5, value=3, step=1, label=\"Few-shot k\")\n",
        "        max_tokens = gr.Slider(100, 2000, value=600, step=50, label=\"LLM max_tokens\")\n",
        "\n",
        "    ask = gr.Button(\"Ask MedIntellAgent\")\n",
        "\n",
        "    sql_out = gr.Code(label=\"Generated SQL\", language=\"sql\")\n",
        "    table_out = gr.Dataframe(label=\"Postgres Results\", interactive=False)\n",
        "    summary_out = gr.Markdown(label=\"LLM Summary\")\n",
        "\n",
        "    ask.click(medintellagent_ui,\n",
        "              inputs=[patient, question, k, max_tokens],\n",
        "              outputs=[sql_out, table_out, summary_out])\n",
        "\n",
        "demo.launch(share=True)   # share=True if you want a temporary public link\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 609
        },
        "id": "9ueifpCk4wbK",
        "outputId": "97dc0656-77d7-4f33-91fa-b6018cd3e21f"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://bee96f7a1bdc08189d.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://bee96f7a1bdc08189d.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluation\n",
        "\n",
        "\n",
        "\n",
        "1.   For now we will use Open AI as LLM for generating Optimized response summary, and score evaluation. Down the line we may change this to e.g. Calude\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "YwYyBHF4pgma"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "pip install -U langgraph"
      ],
      "metadata": {
        "id": "tzpEi4mhpmMU"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "pip install -U langchain_core langchain_openai"
      ],
      "metadata": {
        "id": "nzIacpFAp2Gj"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pydantic import BaseModel, Field"
      ],
      "metadata": {
        "id": "sqowpx_6qVYH"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)"
      ],
      "metadata": {
        "id": "A8rw9eQ6u8lQ"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import TypedDict\n",
        "from typing import Literal\n",
        "import pandas as pd\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "\n",
        "\n",
        "def generate_empathy_score(user_query: str, response: str):\n",
        "\n",
        "    #Graph State\n",
        "    class State(TypedDict):\n",
        "      user_query: str\n",
        "      response: str\n",
        "      empathy_score: str\n",
        "      is_empathetic: bool\n",
        "\n",
        "\n",
        "    #Schema for structured outout to use in evaluation\n",
        "    class Feedback(BaseModel):\n",
        "      score: Literal [\"1\",\"2\",\"3\",\"4\",\"5\"] = Field(\n",
        "          description=\"Provide a score for how empathetic is the response. 5 is highest empathy.\"\n",
        "      )\n",
        "      feedback: str = Field(\n",
        "          description=\"Provide a score for how empathetic is the response. Score of 1: response has no empathy. Score of 5: response has excellent empathy for a human.\"\n",
        "\n",
        "      )\n",
        "\n",
        "    evaluator = llm.with_structured_output(Feedback)\n",
        "\n",
        "    seeded_data = {\n",
        "    \"user_query\": user_query,\n",
        "    \"response\": response\n",
        "    }\n",
        "    # --- 3. CREATE PROMPT TEMPLATE ---\n",
        "\n",
        "    # Define the evaluation instructions using a system message and placeholders\n",
        "    prompt_template = ChatPromptTemplate.from_messages(\n",
        "        [\n",
        "            (\n",
        "                \"system\",\n",
        "                \"\"\"You are an expert, highly empathetic evaluator.\n",
        "                Your task is to judge the system generated response to a user (patient) query.\n",
        "                You must provide a score (1-5) and detailed feedback on the empathy level of the response, strictly following the provided JSON schema.\n",
        "\n",
        "                --- Context ---\n",
        "                User Query: {user_query}\n",
        "                Response to Evaluate: {response}\n",
        "                \"\"\"\n",
        "            ),\n",
        "            (\"human\", \"Evaluate the response for empathy and provide the JSON output.\")\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    # Prepare the data for the prompt\n",
        "    # We convert the table to a string for the prompt\n",
        "    prompt_data = {\n",
        "        \"user_query\": seeded_data[\"user_query\"],\n",
        "        \"response\": seeded_data[\"response\"]\n",
        "    }\n",
        "\n",
        "    # --- 4. RUN EVALUATION ---\n",
        "\n",
        "    # Create the runnable chain: Prompt -> LLM with Structured Output\n",
        "    evaluation_chain = prompt_template | evaluator\n",
        "\n",
        "    # Invoke the chain\n",
        "    try:\n",
        "        evaluation_result: Feedback = evaluation_chain.invoke(prompt_data)\n",
        "\n",
        "        # Output the result\n",
        "        print(\"--- EVALUATION RESULT ---\")\n",
        "        print(f\"Empathy Score: {evaluation_result.score}/5\")\n",
        "        print(f\"Feedback: {evaluation_result.feedback}\")\n",
        "\n",
        "        return {\"empathy_score\": evaluation_result.score, \"feedback\": evaluation_result.feedback}\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred during evaluation: {e}\")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "i0J5KTEGsBWc"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Testing of empathy score\n",
        "\n",
        "patient_id = '0fca905f-391c-08d3-4b93-b53f69b9da53'\n",
        "user_q = 'which medication am I taking?'\n",
        "\n",
        "sql, rows = answer_patient_question(user_q, patient_id, k=5, max_tokens=1000)\n",
        "df = pd.DataFrame(rows)\n",
        "summary = summarize_df_with_llm(df, patient_id=patient_id, model=LLM_MODEL)\n"
      ],
      "metadata": {
        "id": "NxuLeJz-1Elo"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "summary"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "id": "SBWMFpZw2lDX",
        "outputId": "f17947d8-bef2-4420-da67-53bdd86ea6aa"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'The table shows medication data for a single patient (ID: 0fca905f-391c-08d3-4b93-b53f69b9da53) with five entries. All medications listed, including Acetaminophen, oxyCODONE, and amLODIPine, have unspecified start and end dates, as well as no refill information. Notably, there is a gap in the dosage for Naproxen sodium. The data appears truncated, as only five rows are shown.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "generate_empathy_score(user_q,summary)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hvJOqIke2XHe",
        "outputId": "0b76b271-2c25-4eeb-e98f-be2d7b5e2bd2"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- EVALUATION RESULT ---\n",
            "Empathy Score: 1/5\n",
            "Feedback: The response lacks any empathetic language or acknowledgment of the user's situation. It is purely factual and does not address the user's need for clarity or reassurance regarding their medication. There is no attempt to connect with the user on an emotional level or to provide support, making it feel cold and impersonal.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'empathy_score': '1',\n",
              " 'feedback': \"The response lacks any empathetic language or acknowledgment of the user's situation. It is purely factual and does not address the user's need for clarity or reassurance regarding their medication. There is no attempt to connect with the user on an emotional level or to provide support, making it feel cold and impersonal.\"}"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "user_q = 'List all my vital signs'\n",
        "\n",
        "sql, rows = answer_patient_question(user_q, patient_id, k=5, max_tokens=1000)\n",
        "df = pd.DataFrame(rows)\n",
        "summary = summarize_df_with_llm(df, patient_id=patient_id, model=LLM_MODEL)"
      ],
      "metadata": {
        "id": "4_rvk_Bn3Jrs"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "summary"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        },
        "id": "4QORKS-m3Xt7",
        "outputId": "91f23cdb-b0df-41ef-caf1-fa228921a518"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'The data for patient 0fca905f-391c-08d3-4b93-b53f69b9da53 includes 56 rows of vital measurements, with the most recent entries dated April 21, 2025. Notable trends include a decrease in Body Weight from 102 kg in April 2023 to 95.4 kg in April 2025, and a corresponding decrease in Body Mass Index (BMI) from 30.33 kg/m² to 28.35 kg/m². Heart rate values show variability, with a high of 99 beats per minute in March 2017 and a recent low of 69 beats per minute in April 2025. There are gaps in the data for Body Temperature, which is only recorded once in June 2017. The table appears to be truncated, showing 56 rows.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "generate_empathy_score(user_q,summary)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zh7n6RT03cBV",
        "outputId": "188a49c0-7864-41bc-8221-12cfc3e6a34b"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- EVALUATION RESULT ---\n",
            "Empathy Score: 2/5\n",
            "Feedback: The response provides factual information about the user's vital signs but lacks any empathetic language or acknowledgment of the user's feelings or concerns. It presents data in a clinical manner without addressing the user's potential anxiety or curiosity about their health. A more empathetic response would include reassurance, an invitation for the user to ask questions, or a recognition of the importance of these measurements to the user's overall well-being.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'empathy_score': '2',\n",
              " 'feedback': \"The response provides factual information about the user's vital signs but lacks any empathetic language or acknowledgment of the user's feelings or concerns. It presents data in a clinical manner without addressing the user's potential anxiety or curiosity about their health. A more empathetic response would include reassurance, an invitation for the user to ask questions, or a recognition of the importance of these measurements to the user's overall well-being.\"}"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "user_q = 'what has been my weight history'\n",
        "\n",
        "sql, rows = answer_patient_question(user_q, patient_id, k=5, max_tokens=1000)\n",
        "df = pd.DataFrame(rows)\n",
        "summary = summarize_df_with_llm(df, patient_id=patient_id, model=LLM_MODEL)"
      ],
      "metadata": {
        "id": "mey2f4Kc32_K"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "summary"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        },
        "id": "esxH3K4_3_X6",
        "outputId": "3ab04e61-c75e-4340-fef8-dbae60a15148"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'The data shows a trend of fluctuating body weight for the patient over several years, with the most recent measurement on April 21, 2025, at 95.4 kg. Notably, there was a peak weight of 102 kg recorded in both April 2023 and March 2018. The values indicate a general decrease in weight from 102 kg in 2023 to 95.4 kg in 2025, suggesting a potential weight loss trend. There are no entries for vital signs other than body weight, and the table is truncated, showing only 11 rows.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "score_response = generate_empathy_score(user_q,summary)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U5vOUJot4CUx",
        "outputId": "2aadc979-7115-41ac-8daa-66c1f65c10bb"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- EVALUATION RESULT ---\n",
            "Empathy Score: 2/5\n",
            "Feedback: The response provides factual information about the user's weight history, including specific measurements and trends. However, it lacks empathy and emotional support. It does not acknowledge the user's feelings or concerns regarding their weight history, nor does it offer encouragement or understanding. A more empathetic response would include validation of the user's experience and perhaps a supportive comment about their weight loss trend.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(score_response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Od2GJ9Gf4Mz9",
        "outputId": "af41674f-7d3e-4870-e167-3653866a9eaf"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'empathy_score': '2', 'feedback': \"The response provides factual information about the user's weight history, including specific measurements and trends. However, it lacks empathy and emotional support. It does not acknowledge the user's feelings or concerns regarding their weight history, nor does it offer encouragement or understanding. A more empathetic response would include validation of the user's experience and perhaps a supportive comment about their weight loss trend.\"}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Now after these trial runs we aspire to optimize the empathy score"
      ],
      "metadata": {
        "id": "iArup5c27XRS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import TypedDict, Literal, Optional\n",
        "import pandas as pd\n",
        "from pydantic import BaseModel, Field\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_core.messages import SystemMessage, HumanMessage # NEW IMPORT\n",
        "from langgraph.graph import StateGraph, START, END\n",
        "\n",
        "# --- 1. CONFIGURATION AND SCHEMA ---\n",
        "\n",
        "# Note: This requires the OPENAI_API_KEY environment variable to be set.\n",
        "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
        "\n",
        "# 1.1 Graph State (TypedDict)\n",
        "class PatientState(TypedDict):\n",
        "    \"\"\"The state of the conversation and evaluation.\"\"\"\n",
        "    patient_query: str\n",
        "    patient_data: str # Using str to hold Markdown representation of DataFrame\n",
        "    response: str\n",
        "    empathy_score: int\n",
        "    evaluation_feedback: str\n",
        "    retry_count: int\n",
        "\n",
        "# 1.2 Structured Output Schema (Pydantic)\n",
        "class EmpathyEvaluation(BaseModel):\n",
        "    \"\"\"Schema for the structured output of the evaluation LLM.\"\"\"\n",
        "    score: Literal[1, 2, 3, 4, 5] = Field(\n",
        "        description=\"The empathy score for the response (1=low empathy, 5=high empathy).\"\n",
        "    )\n",
        "    feedback: str = Field(\n",
        "        description=\"Constructive, actionable feedback on how to improve the response's empathy, especially if the score is 3 or less.\"\n",
        "    )\n",
        "\n",
        "# Augment the LLM for structured evaluation output\n",
        "evaluator_llm = llm.with_structured_output(EmpathyEvaluation)\n",
        "\n",
        "\n",
        "# --- 2. GRAPH NODES ---\n",
        "\n",
        "def generate_response(state: PatientState) -> dict:\n",
        "    \"\"\"\n",
        "    Node 1: Generates or regenerates a patient response using the LLM.\n",
        "    \"\"\"\n",
        "    print(f\"\\n--- GENERATING RESPONSE (Retry: {state['retry_count']}) ---\")\n",
        "\n",
        "    # Base instructions content\n",
        "    system_prompt_content = (\n",
        "        \"You are a highly empathetic and professional clinical assistant. \"\n",
        "        \"Your primary goal is to acknowledge the patient's feelings and provide clear, gentle, and helpful next steps. \"\n",
        "        \"The current patient query and their data are provided below. Respond with empathy first.\"\n",
        "    )\n",
        "\n",
        "    # Context message content (always included)\n",
        "    context_message_content = (\n",
        "        f\"Patient Query: {state['patient_query']}\\nPatient Data Snapshot:\\n{state['patient_data']}\"\n",
        "    )\n",
        "\n",
        "    # Determine user prompt content\n",
        "    if state[\"retry_count\"] > 0:\n",
        "        # Retry prompt: incorporate previous feedback\n",
        "        user_prompt_content = (\n",
        "            f\"RETRY RESPONSE. The previous attempt scored {state['empathy_score']}/5. \"\n",
        "            f\"The feedback was: '{state['evaluation_feedback']}'. \"\n",
        "            f\"Write a new response that explicitly addresses this feedback and improves empathy.\"\n",
        "        )\n",
        "    else:\n",
        "        # Initial prompt\n",
        "        user_prompt_content = \"Generate a response.\"\n",
        "\n",
        "    # Construct the final list of BaseMessages (REQUIRED INPUT TYPE)\n",
        "    messages = [\n",
        "        SystemMessage(content=system_prompt_content),\n",
        "        HumanMessage(content=context_message_content),\n",
        "        HumanMessage(content=user_prompt_content)\n",
        "    ]\n",
        "\n",
        "    # Invoke LLM with the list of messages\n",
        "    msg = llm.invoke(messages)\n",
        "\n",
        "    return {\n",
        "        \"response\": msg.content,\n",
        "        \"retry_count\": state[\"retry_count\"] + 1,\n",
        "        \"evaluation_feedback\": \"\" # Clear feedback before next evaluation\n",
        "    }\n",
        "\n",
        "\n",
        "def evaluate_response(state: PatientState) -> dict:\n",
        "    \"\"\"\n",
        "    Node 2: Evaluates the generated response for empathy using the structured LLM.\n",
        "    \"\"\"\n",
        "    print(\"\\n--- EVALUATING RESPONSE ---\")\n",
        "\n",
        "    # Prompt for the structured evaluator\n",
        "    evaluation_prompt = (\n",
        "        f\"Evaluate the following clinical assistant response for empathy on a scale of 1 to 5. \"\n",
        "        f\"Score 1 means cold/robotic. Score 5 means outstanding empathy and warmth. \"\n",
        "        f\"Patient Query: {state['patient_query']}\\n\"\n",
        "        f\"Assistant Response: {state['response']}\"\n",
        "    )\n",
        "\n",
        "    # Invoke the structured LLM\n",
        "    evaluation_result: EmpathyEvaluation = evaluator_llm.invoke(evaluation_prompt)\n",
        "\n",
        "    print(f\"-> Score: {evaluation_result.score}/5\")\n",
        "\n",
        "    return {\n",
        "        \"empathy_score\": evaluation_result.score,\n",
        "        \"evaluation_feedback\": evaluation_result.feedback\n",
        "    }\n",
        "\n",
        "\n",
        "def route_to_retry(state: PatientState) -> str:\n",
        "    \"\"\"\n",
        "    Conditional Edge: Decides whether to loop back for regeneration or end.\n",
        "    \"\"\"\n",
        "    score = state[\"empathy_score\"]\n",
        "    max_retries = 3 # Safety limit to prevent infinite loops\n",
        "\n",
        "    if score > 3:\n",
        "        print(\"\\n*** ROUTE: END (Score > 3) ***\")\n",
        "        return \"end\"\n",
        "    elif state[\"retry_count\"] >= max_retries:\n",
        "        print(f\"\\n*** ROUTE: END (Max Retries ({max_retries}) Reached) ***\")\n",
        "        return \"end\"\n",
        "    else:\n",
        "        print(\"\\n*** ROUTE: RETRY (Score <= 3) ***\")\n",
        "        return \"retry\"\n",
        "\n",
        "\n",
        "# --- 3. WORKFLOW ASSEMBLY AND MAIN FUNCTION ---\n",
        "\n",
        "def optimize_patient_response(query: str, data: pd.DataFrame, max_retries=3):\n",
        "    \"\"\"\n",
        "    Main function to run the optimization graph.\n",
        "\n",
        "    Args:\n",
        "        query (str): The patient's input question or concern.\n",
        "        data (pd.DataFrame): Relevant patient data.\n",
        "        max_retries (int): Maximum number of attempts before stopping.\n",
        "\n",
        "    Returns:\n",
        "        dict: The final state of the graph, including the optimized response.\n",
        "    \"\"\"\n",
        "\n",
        "    # Initialize the graph builder\n",
        "    optimizer_builder = StateGraph(PatientState)\n",
        "\n",
        "    # Add the nodes (actions)\n",
        "    optimizer_builder.add_node(\"generator\", generate_response)\n",
        "    optimizer_builder.add_node(\"evaluator\", evaluate_response)\n",
        "\n",
        "    # Define the entry point\n",
        "    optimizer_builder.add_edge(START, \"generator\")\n",
        "\n",
        "    # Define the flow from generation to evaluation\n",
        "    optimizer_builder.add_edge(\"generator\", \"evaluator\")\n",
        "\n",
        "    # Define the conditional loop after evaluation\n",
        "    optimizer_builder.add_conditional_edges(\n",
        "        \"evaluator\",\n",
        "        route_to_retry,\n",
        "        {\n",
        "            \"retry\": \"generator\", # Loop back to generator\n",
        "            \"end\": END,           # Stop the workflow\n",
        "        }\n",
        "    )\n",
        "\n",
        "    # Compile the workflow\n",
        "    optimizer_workflow = optimizer_builder.compile()\n",
        "\n",
        "    # Initial state preparation\n",
        "    initial_state = {\n",
        "        \"patient_query\": query,\n",
        "        \"patient_data\": data.to_markdown(), # Convert DataFrame head to readable string\n",
        "        \"response\": \"\",\n",
        "        \"empathy_score\": 0,\n",
        "        \"evaluation_feedback\": \"\",\n",
        "        \"retry_count\": 0\n",
        "    }\n",
        "\n",
        "    print(f\"--- STARTING OPTIMIZATION (Max Retries: {max_retries}) ---\")\n",
        "\n",
        "    # Invoke the workflow\n",
        "    final_state = optimizer_workflow.invoke(initial_state, {\"recursion_limit\": max_retries + 2})\n",
        "\n",
        "    return final_state"
      ],
      "metadata": {
        "id": "vboNsPQM8sZR"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "patient_id = '0fca905f-391c-08d3-4b93-b53f69b9da53'\n",
        "user_q = 'which medication am I taking?'\n",
        "\n",
        "sql, rows = answer_patient_question(user_q, patient_id, k=5, max_tokens=1000)\n",
        "df = pd.DataFrame(rows)\n"
      ],
      "metadata": {
        "id": "yHAb_AnLCtu_"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "summary_1 = summarize_df_with_llm(df, patient_id=patient_id, model=LLM_MODEL)"
      ],
      "metadata": {
        "id": "8zrGlpnaEN4-"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "summary_1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "id": "zLLXQndSEZr7",
        "outputId": "df3c7e79-9282-4e8a-90ba-5e3f29c6ad10"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'The table shows medication data for a single patient (ID: 0fca905f-391c-08d3-4b93-b53f69b9da53) with five entries. All medications listed, including Acetaminophen, oxyCODONE, and amLODIPine, have unspecified start and end dates, as well as no refill information. Notably, one entry for Naproxen sodium lacks dosage details. The data appears truncated, as only five rows are shown, and there are gaps in critical fields.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Run the optimization process\n",
        "optimized_result = optimize_patient_response(\n",
        "  query=user_q,\n",
        "  data=df,\n",
        "  max_retries=3 # Will stop after 3 attempts, even if score < 4\n",
        ")\n",
        "\n",
        "print(\"\\n==============================================\")\n",
        "print(\"      FINAL OPTIMIZED RESPONSE & RESULTS\")\n",
        "print(\"==============================================\")\n",
        "print(f\"Query: {optimized_result['patient_query']}\")\n",
        "print(f\"Final Score: {optimized_result['empathy_score']}/5\")\n",
        "print(f\"Final Response:\\n{optimized_result['response']}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N2_qxDHQDIJR",
        "outputId": "37c39372-8704-4177-bddc-29bd10647084"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- STARTING OPTIMIZATION (Max Retries: 3) ---\n",
            "\n",
            "--- GENERATING RESPONSE (Retry: 0) ---\n",
            "\n",
            "--- EVALUATING RESPONSE ---\n",
            "-> Score: 4/5\n",
            "\n",
            "*** ROUTE: END (Score > 3) ***\n",
            "\n",
            "==============================================\n",
            "      FINAL OPTIMIZED RESPONSE & RESULTS\n",
            "==============================================\n",
            "Query: which medication am I taking?\n",
            "Final Score: 4/5\n",
            "Final Response:\n",
            "I understand that it can be a bit confusing to keep track of your medications, and I'm here to help you with that. Based on your records, you are currently taking the following medications:\n",
            "\n",
            "1. **Acetaminophen 325 MG Oral Tablet (Tylenol)**\n",
            "2. **Acetaminophen 325 MG / OxyCODONE Hydrochloride 5 MG Oral Tablet**\n",
            "3. **Amlodipine 2.5 MG Oral Tablet**\n",
            "4. **Naproxen Sodium 220 MG Oral Tablet**\n",
            "\n",
            "If you have any questions about these medications, such as their purposes or how to take them, please feel free to ask. It's important to feel comfortable and informed about your treatment.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Test 2**\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "gwaRwHIbEzI6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "patient_id = '0fca905f-391c-08d3-4b93-b53f69b9da53'\n",
        "user_q = 'what has been my weight history'\n",
        "\n",
        "sql, rows = answer_patient_question(user_q, patient_id, k=5, max_tokens=1000)\n",
        "df = pd.DataFrame(rows)\n",
        "summary = summarize_df_with_llm(df, patient_id=patient_id, model=LLM_MODEL)"
      ],
      "metadata": {
        "id": "PjEHywBuFQC0"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "summary"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        },
        "id": "KDveHomVFnpH",
        "outputId": "2f71342d-f13e-4b26-fcaa-97be2a3339b4"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'The data for patient 0fca905f-391c-08d3-4b93-b53f69b9da53 shows a trend of fluctuating body weight over the years, with the most recent measurement on April 21, 2025, at 95.4 kg. Notably, there was a peak weight of 102 kg recorded in both April 2023 and March 2018. The values indicate a general decrease in weight from 102 kg in 2023 to 95.4 kg in 2025, suggesting a potential weight loss trend. There are no entries for vital signs other than body weight, indicating a gap in the data. The table shows 11 rows of data.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Run the optimization process\n",
        "optimized_result = optimize_patient_response(\n",
        "  query=user_q,\n",
        "  data=df,\n",
        "  max_retries=3 # Will stop after 3 attempts, even if score < 4\n",
        ")\n",
        "\n",
        "print(\"\\n==============================================\")\n",
        "print(\"      FINAL OPTIMIZED RESPONSE & RESULTS\")\n",
        "print(\"==============================================\")\n",
        "print(f\"Query: {optimized_result['patient_query']}\")\n",
        "print(f\"Final Score: {optimized_result['empathy_score']}/5\")\n",
        "print(f\"Final Response:\\n{optimized_result['response']}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jS2RDRHSFvqH",
        "outputId": "1ef2c464-2bb5-43de-b580-5c8b39e723c1"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- STARTING OPTIMIZATION (Max Retries: 3) ---\n",
            "\n",
            "--- GENERATING RESPONSE (Retry: 0) ---\n",
            "\n",
            "--- EVALUATING RESPONSE ---\n",
            "-> Score: 4/5\n",
            "\n",
            "*** ROUTE: END (Score > 3) ***\n",
            "\n",
            "==============================================\n",
            "      FINAL OPTIMIZED RESPONSE & RESULTS\n",
            "==============================================\n",
            "Query: what has been my weight history\n",
            "Final Score: 4/5\n",
            "Final Response:\n",
            "I understand that tracking your weight history can be important for your health and well-being, and I appreciate you reaching out about this. Here’s a summary of your weight history over the past several years:\n",
            "\n",
            "- **2025-04-21**: 95.4 kg\n",
            "- **2024-04-15**: 95.1 kg\n",
            "- **2023-04-10**: 102 kg\n",
            "- **2022-04-04**: 99.6 kg\n",
            "- **2021-03-29**: 97.3 kg\n",
            "- **2020-11-16**: 96.4 kg\n",
            "- **2020-03-23**: 94.9 kg\n",
            "- **2019-03-18**: 95.2 kg\n",
            "- **2018-03-12**: 102 kg\n",
            "- **2017-03-06**: 100 kg\n",
            "- **2016-02-29**: 98.1 kg\n",
            "\n",
            "It looks like your weight has fluctuated over the years, with some notable changes. If you have any specific concerns or goals regarding your weight, or if you would like to discuss this further, please let me know. I'm here to help you with any next steps or support you may need.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2ga262L4F97M"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Test 3**"
      ],
      "metadata": {
        "id": "dcAvOSz-F_X-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "patient_id = '0fca905f-391c-08d3-4b93-b53f69b9da53'\n",
        "user_q = 'List all my vital signs'\n",
        "\n",
        "sql, rows = answer_patient_question(user_q, patient_id, k=5, max_tokens=1000)\n",
        "df = pd.DataFrame(rows)\n",
        "summary = summarize_df_with_llm(df, patient_id=patient_id, model=LLM_MODEL)"
      ],
      "metadata": {
        "id": "Wsq58W_mGDJO"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "summary"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 103
        },
        "id": "FZzPCIcAGRJE",
        "outputId": "9d0e6136-e2b8-44c1-f7a9-be8c9fec2907"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'The data for patient 0fca905f-391c-08d3-4b93-b53f69b9da53 includes 56 rows of vital measurements, with the most recent entries dated April 21, 2025. Notable trends include a decrease in Body Weight from 102 kg in April 2023 to 95.4 kg in April 2025, and a corresponding decrease in Body Mass Index (BMI) from 30.33 kg/m² to 28.35 kg/m². Heart rate has fluctuated, with a notable drop from 88 beats per minute in April 2023 to 69 in April 2025. There are no entries for body temperature in the recent data, indicating a potential gap in monitoring this vital sign. The table appears to be truncated, showing only 56 rows.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Run the optimization process\n",
        "optimized_result = optimize_patient_response(\n",
        "  query=user_q,\n",
        "  data=df,\n",
        "  max_retries=3 # Will stop after 3 attempts, even if score < 4\n",
        ")\n",
        "\n",
        "print(\"\\n==============================================\")\n",
        "print(\"      FINAL OPTIMIZED RESPONSE & RESULTS\")\n",
        "print(\"==============================================\")\n",
        "print(f\"Query: {optimized_result['patient_query']}\")\n",
        "print(f\"Final Score: {optimized_result['empathy_score']}/5\")\n",
        "print(f\"Final Response:\\n{optimized_result['response']}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QrYlLS26GVm8",
        "outputId": "1229783b-6a19-479a-db57-526f8f789827"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- STARTING OPTIMIZATION (Max Retries: 3) ---\n",
            "\n",
            "--- GENERATING RESPONSE (Retry: 0) ---\n",
            "\n",
            "--- EVALUATING RESPONSE ---\n",
            "-> Score: 4/5\n",
            "\n",
            "*** ROUTE: END (Score > 3) ***\n",
            "\n",
            "==============================================\n",
            "      FINAL OPTIMIZED RESPONSE & RESULTS\n",
            "==============================================\n",
            "Query: List all my vital signs\n",
            "Final Score: 4/5\n",
            "Final Response:\n",
            "I understand that you’re looking for a comprehensive overview of your vital signs, and I’m here to help you with that. It’s important to keep track of these measurements as they can provide valuable insights into your health.\n",
            "\n",
            "Here’s a summary of your vital signs:\n",
            "\n",
            "1. **Body Height**: \n",
            "   - 183.4 cm (most recent measurement on April 21, 2025)\n",
            "\n",
            "2. **Body Weight**: \n",
            "   - 95.4 kg (most recent measurement on April 21, 2025)\n",
            "\n",
            "3. **Body Mass Index (BMI)**: \n",
            "   - 28.35 kg/m² (most recent measurement on April 21, 2025)\n",
            "\n",
            "4. **Heart Rate**: \n",
            "   - 69 beats per minute (most recent measurement on April 21, 2025)\n",
            "\n",
            "5. **Respiratory Rate**: \n",
            "   - 14 breaths per minute (most recent measurement on April 21, 2025)\n",
            "\n",
            "If you have any specific concerns or if you would like to discuss these values further, please feel free to share. Your health is important, and I’m here to support you in any way I can.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Test 4**"
      ],
      "metadata": {
        "id": "iQONTKjBGzpJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "patient_id = '0fca905f-391c-08d3-4b93-b53f69b9da53'\n",
        "user_q = 'Show my BMI trend'\n",
        "\n",
        "sql, rows = answer_patient_question(user_q, patient_id, k=5, max_tokens=1000)\n",
        "df = pd.DataFrame(rows)\n",
        "summary = summarize_df_with_llm(df, patient_id=patient_id, model=LLM_MODEL)"
      ],
      "metadata": {
        "id": "DWq-amwaG36j"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "summary"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "id": "PBb6nCkTHGkE",
        "outputId": "49a0eefc-b58f-42bf-90ec-42212d4ecbaf"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'The data shows a trend of decreasing Body Mass Index (BMI) values over the last several years, with the most recent measurement on April 21, 2025, at 28.35 kg/m², down from a peak of 30.33 kg/m² on April 10, 2023. Notably, the BMI has decreased from 30.32 kg/m² in 2018 to 28.35 kg/m² in 2025. There are no gaps in the vital measurements, but the data is truncated, showing only 11 rows.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Run the optimization process\n",
        "optimized_result = optimize_patient_response(\n",
        "  query=user_q,\n",
        "  data=df,\n",
        "  max_retries=3 # Will stop after 3 attempts, even if score < 4\n",
        ")\n",
        "\n",
        "print(\"\\n==============================================\")\n",
        "print(\"      FINAL OPTIMIZED RESPONSE & RESULTS\")\n",
        "print(\"==============================================\")\n",
        "print(f\"Query: {optimized_result['patient_query']}\")\n",
        "print(f\"Final Score: {optimized_result['empathy_score']}/5\")\n",
        "print(f\"Final Response:\\n{optimized_result['response']}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aNM_0lizHKKK",
        "outputId": "42a56ca2-14d2-4b0a-e95e-c7e84d12a323"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- STARTING OPTIMIZATION (Max Retries: 3) ---\n",
            "\n",
            "--- GENERATING RESPONSE (Retry: 0) ---\n",
            "\n",
            "--- EVALUATING RESPONSE ---\n",
            "-> Score: 4/5\n",
            "\n",
            "*** ROUTE: END (Score > 3) ***\n",
            "\n",
            "==============================================\n",
            "      FINAL OPTIMIZED RESPONSE & RESULTS\n",
            "==============================================\n",
            "Query: Show my BMI trend\n",
            "Final Score: 4/5\n",
            "Final Response:\n",
            "I understand that tracking your BMI trend can be important for your health and wellness journey. It’s great that you’re taking the time to monitor these changes. \n",
            "\n",
            "Here’s a summary of your BMI trend over the past few years:\n",
            "\n",
            "- **2025-04-21**: 28.35 kg/m²\n",
            "- **2024-04-15**: 28.26 kg/m²\n",
            "- **2023-04-10**: 30.33 kg/m²\n",
            "- **2022-04-04**: 29.62 kg/m²\n",
            "- **2021-03-29**: 28.91 kg/m²\n",
            "- **2020-11-16**: 28.66 kg/m²\n",
            "- **2020-03-23**: 28.21 kg/m²\n",
            "- **2019-03-18**: 28.31 kg/m²\n",
            "- **2018-03-12**: 30.32 kg/m²\n",
            "- **2017-03-06**: 29.74 kg/m²\n",
            "- **2016-02-29**: 29.16 kg/m²\n",
            "\n",
            "From this data, we can see that your BMI has shown some fluctuations over the years, with a noticeable decrease from 30.33 kg/m² in 2023 to 28.35 kg/m² in 2025. This trend may indicate positive changes in your health or lifestyle.\n",
            "\n",
            "If you have any specific questions about your BMI or if you’d like to discuss any goals or concerns related to your health, please feel free to share. I'm here to help you with the next steps!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Test 5**"
      ],
      "metadata": {
        "id": "vZw-lGpoHXbj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "patient_id = '0fca905f-391c-08d3-4b93-b53f69b9da53'\n",
        "user_q = 'Give me my blood pressure readings over time'\n",
        "\n",
        "sql, rows = answer_patient_question(user_q, patient_id, k=5, max_tokens=1000)\n",
        "df = pd.DataFrame(rows)\n",
        "summary = summarize_df_with_llm(df, patient_id=patient_id, model=LLM_MODEL)\n",
        "print(\"Non-optimized summary: \\n\",summary)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vJfCgr_DHdTH",
        "outputId": "5b6bcbe2-f628-4809-ea84-8b800c304fae"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Non-optimized summary: \n",
            " No data found for the requested query.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Run the optimization process\n",
        "optimized_result = optimize_patient_response(\n",
        "  query=user_q,\n",
        "  data=df,\n",
        "  max_retries=3 # Will stop after 3 attempts, even if score < 4\n",
        ")\n",
        "\n",
        "print(\"\\n==============================================\")\n",
        "print(\"      FINAL OPTIMIZED RESPONSE & RESULTS\")\n",
        "print(\"==============================================\")\n",
        "print(f\"Query: {optimized_result['patient_query']}\")\n",
        "print(f\"Final Score: {optimized_result['empathy_score']}/5\")\n",
        "print(f\"Final Response:\\n{optimized_result['response']}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qyeS6Na2H-MZ",
        "outputId": "7144a5c4-eeab-48e8-c387-1d93929acead"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- STARTING OPTIMIZATION (Max Retries: 3) ---\n",
            "\n",
            "--- GENERATING RESPONSE (Retry: 0) ---\n",
            "\n",
            "--- EVALUATING RESPONSE ---\n",
            "-> Score: 4/5\n",
            "\n",
            "*** ROUTE: END (Score > 3) ***\n",
            "\n",
            "==============================================\n",
            "      FINAL OPTIMIZED RESPONSE & RESULTS\n",
            "==============================================\n",
            "Query: Give me my blood pressure readings over time\n",
            "Final Score: 4/5\n",
            "Final Response:\n",
            "I understand that keeping track of your blood pressure readings is important for your health, and it can be concerning if you’re unsure about your numbers over time. Unfortunately, I don’t have access to your specific blood pressure readings at the moment. \n",
            "\n",
            "However, I recommend checking with your healthcare provider or the facility where you have your readings recorded. They should be able to provide you with a detailed history of your blood pressure measurements. \n",
            "\n",
            "If you have been keeping a personal log or using a home monitor, reviewing that data can also be very helpful. If you have any questions about what your readings mean or how to manage your blood pressure, please feel free to ask. I'm here to help!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Test 6**"
      ],
      "metadata": {
        "id": "xOrrMTEcIz--"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "patient_id = '0fca905f-391c-08d3-4b93-b53f69b9da53'\n",
        "user_q = 'What conditions have I been diagnosed with?'\n",
        "\n",
        "sql, rows = answer_patient_question(user_q, patient_id, k=5, max_tokens=1000)\n",
        "df = pd.DataFrame(rows)\n",
        "summary = summarize_df_with_llm(df, patient_id=patient_id, model=LLM_MODEL)\n",
        "print(\"Non-optimized summary: \\n\",summary)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0ZQh8pkwI30X",
        "outputId": "4d0d0f6c-4a7d-43e1-d822-2ca1a427ef6a"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Non-optimized summary: \n",
            " The table shows 21 rows of patient data, with a mix of resolved and active conditions. Notably, there are 10 active findings, including full-time and part-time employment statuses, chronic low back pain, and social isolation, which may indicate ongoing challenges. Resolved conditions include various dental and viral disorders, with the most recent resolution occurring in 2024. There are several gaps in the data, particularly for the active conditions, which lack resolution dates.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Run the optimization process\n",
        "optimized_result = optimize_patient_response(\n",
        "  query=user_q,\n",
        "  data=df,\n",
        "  max_retries=3 # Will stop after 3 attempts, even if score < 4\n",
        ")\n",
        "\n",
        "print(\"\\n==============================================\")\n",
        "print(\"      FINAL OPTIMIZED RESPONSE & RESULTS\")\n",
        "print(\"==============================================\")\n",
        "print(f\"Query: {optimized_result['patient_query']}\")\n",
        "print(f\"Final Score: {optimized_result['empathy_score']}/5\")\n",
        "print(f\"Final Response:\\n{optimized_result['response']}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y6v24IPgJNDg",
        "outputId": "34a1e0e1-e909-4a5c-ab13-102957e92338"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- STARTING OPTIMIZATION (Max Retries: 3) ---\n",
            "\n",
            "--- GENERATING RESPONSE (Retry: 0) ---\n",
            "\n",
            "--- EVALUATING RESPONSE ---\n",
            "-> Score: 4/5\n",
            "\n",
            "*** ROUTE: END (Score > 3) ***\n",
            "\n",
            "==============================================\n",
            "      FINAL OPTIMIZED RESPONSE & RESULTS\n",
            "==============================================\n",
            "Query: What conditions have I been diagnosed with?\n",
            "Final Score: 4/5\n",
            "Final Response:\n",
            "I understand that it can be concerning to keep track of your health conditions, and I'm here to help you with that. Based on your records, here are the conditions you have been diagnosed with:\n",
            "\n",
            "**Active Conditions:**\n",
            "1. **Body Mass Index 30+ - Obesity**\n",
            "2. **Chronic Low Back Pain**\n",
            "3. **Essential Hypertension**\n",
            "4. **Social Isolation**\n",
            "5. **Limited Social Contact**\n",
            "6. **Victim of Intimate Partner Abuse**\n",
            "7. **Stress**\n",
            "8. **Chronic Pain**\n",
            "9. **Has a Criminal Record**\n",
            "\n",
            "**Resolved Conditions:**\n",
            "1. **Primary Dental Caries**\n",
            "2. **Gingival Disease**\n",
            "3. **Acute Viral Pharyngitis**\n",
            "4. **Viral Sinusitis**\n",
            "5. **Gingivitis**\n",
            "6. **Traumatic Dislocation of Temporomandibular Joint**\n",
            "7. **Medication Review Due**\n",
            "\n",
            "If you have any questions about these conditions or need support in managing them, please feel free to ask. Your health and well-being are important, and I'm here to assist you in any way I can.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Test 7**"
      ],
      "metadata": {
        "id": "mVngi0xuJlly"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "patient_id = '0fca905f-391c-08d3-4b93-b53f69b9da53'\n",
        "user_q = 'How screwed up am I? '\n",
        "\n",
        "sql, rows = answer_patient_question(user_q, patient_id, k=5, max_tokens=1000)\n",
        "df = pd.DataFrame(rows)\n",
        "summary = summarize_df_with_llm(df, patient_id=patient_id, model=LLM_MODEL)\n",
        "print(\"Non-optimized summary: \\n\",summary)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hvNq6dfDJtjd",
        "outputId": "f59e788d-fee2-4ba4-ee76-748e63b7946a"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Non-optimized summary: \n",
            " No data found for the requested query.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        },
        "id": "RpAWmhszKRk-",
        "outputId": "571c4058-98c0-4a10-92df-fbac231c0339"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Empty DataFrame\n",
              "Columns: []\n",
              "Index: []"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-7872c217-e845-4082-83bd-0a7e9cd113a5\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7872c217-e845-4082-83bd-0a7e9cd113a5')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-7872c217-e845-4082-83bd-0a7e9cd113a5 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-7872c217-e845-4082-83bd-0a7e9cd113a5');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "  <div id=\"id_9198fea2-3781-479e-952d-3f7934b77bdd\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_9198fea2-3781-479e-952d-3f7934b77bdd button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 0,\n  \"fields\": []\n}"
            }
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Run the optimization process\n",
        "optimized_result = optimize_patient_response(\n",
        "  query=user_q,\n",
        "  data=df,\n",
        "  max_retries=3 # Will stop after 3 attempts, even if score < 4\n",
        ")\n",
        "\n",
        "print(\"\\n==============================================\")\n",
        "print(\"      FINAL OPTIMIZED RESPONSE & RESULTS\")\n",
        "print(\"==============================================\")\n",
        "print(f\"Query: {optimized_result['patient_query']}\")\n",
        "print(f\"Final Score: {optimized_result['empathy_score']}/5\")\n",
        "print(f\"Final Response:\\n{optimized_result['response']}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5vIzcf2RJ6Hh",
        "outputId": "613419f6-40ce-42a3-adf8-d89e69d468f1"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- STARTING OPTIMIZATION (Max Retries: 3) ---\n",
            "\n",
            "--- GENERATING RESPONSE (Retry: 0) ---\n",
            "\n",
            "--- EVALUATING RESPONSE ---\n",
            "-> Score: 5/5\n",
            "\n",
            "*** ROUTE: END (Score > 3) ***\n",
            "\n",
            "==============================================\n",
            "      FINAL OPTIMIZED RESPONSE & RESULTS\n",
            "==============================================\n",
            "Query: How screwed up am I? \n",
            "Final Score: 5/5\n",
            "Final Response:\n",
            "I want to start by acknowledging how you're feeling right now. It’s completely normal to have moments of self-doubt or to feel overwhelmed, and it’s brave of you to reach out. Remember, everyone goes through tough times, and it doesn’t define who you are or your potential for healing and growth.\n",
            "\n",
            "If you’re comfortable, I’d like to understand more about what’s been on your mind or what specific concerns you have. This can help us identify some next steps together. You’re not alone in this, and there are ways to find support and clarity.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Test 8**"
      ],
      "metadata": {
        "id": "o_387LgoKeqo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "patient_id = '0fca905f-391c-08d3-4b93-b53f69b9da53'\n",
        "user_q = 'LIST my active prescriptions'\n",
        "\n",
        "sql, rows = answer_patient_question(user_q, patient_id, k=5, max_tokens=1000)\n",
        "df = pd.DataFrame(rows)\n",
        "summary = summarize_df_with_llm(df, patient_id=patient_id, model=LLM_MODEL)\n",
        "print(\"Non-optimized summary: \\n\",summary)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yS3r4Ba6KmRo",
        "outputId": "05c61c0c-3253-40a0-bc3a-a29a34c29e01"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Non-optimized summary: \n",
            " The table shows medication records for a single patient (ID: 0fca905f-391c-08d3-4b93-b53f69b9da53) with five entries. All medications listed, including Acetaminophen, oxyCODONE, and amLODIPine, have a dose of 1.0, but the route, start and end dates, and refills are not provided (marked as \"—\"). Notably, there is a gap in the data regarding the administration details and duration of treatment. The table is truncated, showing only 5 rows.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Run the optimization process\n",
        "optimized_result = optimize_patient_response(\n",
        "  query=user_q,\n",
        "  data=df,\n",
        "  max_retries=3 # Will stop after 3 attempts, even if score < 4\n",
        ")\n",
        "\n",
        "print(\"\\n==============================================\")\n",
        "print(\"      FINAL OPTIMIZED RESPONSE & RESULTS\")\n",
        "print(\"==============================================\")\n",
        "print(f\"Query: {optimized_result['patient_query']}\")\n",
        "print(f\"Final Score: {optimized_result['empathy_score']}/5\")\n",
        "print(f\"Final Response:\\n{optimized_result['response']}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7vzHiM1DKwUW",
        "outputId": "437bad5c-3f7d-4d85-eddc-265fec44c653"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- STARTING OPTIMIZATION (Max Retries: 3) ---\n",
            "\n",
            "--- GENERATING RESPONSE (Retry: 0) ---\n",
            "\n",
            "--- EVALUATING RESPONSE ---\n",
            "-> Score: 4/5\n",
            "\n",
            "*** ROUTE: END (Score > 3) ***\n",
            "\n",
            "==============================================\n",
            "      FINAL OPTIMIZED RESPONSE & RESULTS\n",
            "==============================================\n",
            "Query: LIST my active prescriptions\n",
            "Final Score: 4/5\n",
            "Final Response:\n",
            "I understand that keeping track of your medications can be overwhelming at times, and I'm here to help you with that. Here’s a list of your active prescriptions:\n",
            "\n",
            "1. **Acetaminophen 325 MG Oral Tablet [Tylenol]**\n",
            "   - Dose: 1 tablet\n",
            "   - Route: Oral\n",
            "\n",
            "2. **Acetaminophen 325 MG / OxyCODONE Hydrochloride 5 MG Oral Tablet**\n",
            "   - Dose: 1 tablet\n",
            "   - Route: Oral\n",
            "\n",
            "3. **Amlodipine 2.5 MG Oral Tablet**\n",
            "   - Dose: 1 tablet\n",
            "   - Route: Oral\n",
            "\n",
            "4. **Naproxen Sodium 220 MG Oral Tablet**\n",
            "   - Dose: Not specified\n",
            "   - Route: Oral\n",
            "\n",
            "If you have any questions about these medications or need further assistance, please feel free to ask. Your health and comfort are important, and I'm here to support you.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Test 9**"
      ],
      "metadata": {
        "id": "qSKh9ZS_LY5z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "patient_id = '0fca905f-391c-08d3-4b93-b53f69b9da53'\n",
        "user_q = 'Which of my visits have lab results'\n",
        "\n",
        "try:\n",
        "    sql, rows = answer_patient_question(user_q, patient_id, k=5, max_tokens=1000)\n",
        "    df = pd.DataFrame(rows)\n",
        "    summary = summarize_df_with_llm(df, patient_id=patient_id, model=LLM_MODEL)\n",
        "    print(\"Non-optimized summary: \\n\",summary)\n",
        "except Exception as error:\n",
        "    print(error)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PnH0DyaMLb5f",
        "outputId": "484b5ecb-4050-429d-84c5-b1102693f0e4"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Blocked: SQL must be a single SELECT without DDL/DML.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "9w9KOLPJLs71",
        "outputId": "848b5e1e-7b8b-4fad-d1c4-96268aec2711"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                             patient_id  \\\n",
              "0  0fca905f-391c-08d3-4b93-b53f69b9da53   \n",
              "1  0fca905f-391c-08d3-4b93-b53f69b9da53   \n",
              "2  0fca905f-391c-08d3-4b93-b53f69b9da53   \n",
              "3  0fca905f-391c-08d3-4b93-b53f69b9da53   \n",
              "4  0fca905f-391c-08d3-4b93-b53f69b9da53   \n",
              "\n",
              "                                          medication  dose route  \\\n",
              "0         Acetaminophen 325 MG Oral Tablet [Tylenol]   1.0  None   \n",
              "1  Acetaminophen 325 MG / oxyCODONE Hydrochloride...   1.0  None   \n",
              "2                      amLODIPine 2.5 MG Oral Tablet   1.0  None   \n",
              "3                 Naproxen sodium 220 MG Oral Tablet  None  None   \n",
              "4                                               None  None  None   \n",
              "\n",
              "  start_datetime end_datetime refills  \n",
              "0           None         None    None  \n",
              "1           None         None    None  \n",
              "2           None         None    None  \n",
              "3           None         None    None  \n",
              "4           None         None    None  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-fbb4e53d-33ed-4ae6-9e2b-d80c3968060b\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>patient_id</th>\n",
              "      <th>medication</th>\n",
              "      <th>dose</th>\n",
              "      <th>route</th>\n",
              "      <th>start_datetime</th>\n",
              "      <th>end_datetime</th>\n",
              "      <th>refills</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0fca905f-391c-08d3-4b93-b53f69b9da53</td>\n",
              "      <td>Acetaminophen 325 MG Oral Tablet [Tylenol]</td>\n",
              "      <td>1.0</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0fca905f-391c-08d3-4b93-b53f69b9da53</td>\n",
              "      <td>Acetaminophen 325 MG / oxyCODONE Hydrochloride...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0fca905f-391c-08d3-4b93-b53f69b9da53</td>\n",
              "      <td>amLODIPine 2.5 MG Oral Tablet</td>\n",
              "      <td>1.0</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0fca905f-391c-08d3-4b93-b53f69b9da53</td>\n",
              "      <td>Naproxen sodium 220 MG Oral Tablet</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0fca905f-391c-08d3-4b93-b53f69b9da53</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-fbb4e53d-33ed-4ae6-9e2b-d80c3968060b')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-fbb4e53d-33ed-4ae6-9e2b-d80c3968060b button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-fbb4e53d-33ed-4ae6-9e2b-d80c3968060b');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-6795ddc0-8135-4761-9690-5e476970a092\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-6795ddc0-8135-4761-9690-5e476970a092')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-6795ddc0-8135-4761-9690-5e476970a092 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "  <div id=\"id_a1336ffb-7ab1-4a3b-8a1a-8b1f682965dc\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_a1336ffb-7ab1-4a3b-8a1a-8b1f682965dc button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "repr_error": "Out of range float values are not JSON compliant: nan"
            }
          },
          "metadata": {},
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Run the optimization process\n",
        "optimized_result = optimize_patient_response(\n",
        "  query=user_q,\n",
        "  data=df,\n",
        "  max_retries=3 # Will stop after 3 attempts, even if score < 4\n",
        ")\n",
        "\n",
        "print(\"\\n==============================================\")\n",
        "print(\"      FINAL OPTIMIZED RESPONSE & RESULTS\")\n",
        "print(\"==============================================\")\n",
        "print(f\"Query: {optimized_result['patient_query']}\")\n",
        "print(f\"Final Score: {optimized_result['empathy_score']}/5\")\n",
        "print(f\"Final Response:\\n{optimized_result['response']}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s6CHx0knLfXx",
        "outputId": "972b8eb3-b38b-46e9-e29a-7d946b6132fd"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- STARTING OPTIMIZATION (Max Retries: 3) ---\n",
            "\n",
            "--- GENERATING RESPONSE (Retry: 0) ---\n",
            "\n",
            "--- EVALUATING RESPONSE ---\n",
            "-> Score: 5/5\n",
            "\n",
            "*** ROUTE: END (Score > 3) ***\n",
            "\n",
            "==============================================\n",
            "      FINAL OPTIMIZED RESPONSE & RESULTS\n",
            "==============================================\n",
            "Query: Which of my visits have lab results\n",
            "Final Score: 5/5\n",
            "Final Response:\n",
            "I understand that you're looking for information about your visits that include lab results, and I can see how important this information is for you. It’s completely normal to want to keep track of your health and any tests that have been done.\n",
            "\n",
            "To assist you better, I recommend checking your patient portal if you have access to it, as it often contains detailed information about your visits and any associated lab results. If you’re unable to find the information there, please consider reaching out to your healthcare provider’s office directly. They can provide you with a comprehensive list of your visits and any lab results associated with them.\n",
            "\n",
            "If you have any other questions or need further assistance, please feel free to ask. Your health and peace of mind are important!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# LJ empathy optimized response (LLM as a Judge scores optimized response)"
      ],
      "metadata": {
        "id": "d8XilyFYcC-x"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "*   Relevance of response to patient question\n",
        "\n"
      ],
      "metadata": {
        "id": "2db7bq-Te5fk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "user_question = \"When was my last cholesterol test?\"\n",
        "portal_response = \"Your most recent cholesterol test was on May 2, 2024, showing normal results.\"\n",
        "\n",
        "judge_prompt_R = f\"\"\"\n",
        "You are an expert judge that evaluates the quality of a response provided by a patient question-answering LLM system to a patient’s query.\n",
        "Your task is to provide a Relevance score (1–5) for how well the system’s response answers the patient’s question about their own medical history or records.\n",
        "\n",
        "***Criterion Definition***\n",
        "RELEVANCE: The degree to which the response directly and appropriately addresses the specific patient question about their medical record, history, medications, lab results, appointments, or related data.\n",
        "\n",
        "***Score Definitions and Examples***\n",
        "\n",
        "1: NOT RELEVANT\n",
        "- Meaning: The response does not relate to the patient’s question.\n",
        "- Example:\n",
        "  Q: “What medications am I currently taking?”\n",
        "  A: “You should eat a balanced diet.”\n",
        "  → Not relevant.\n",
        "\n",
        "2: SLIGHTLY RELEVANT\n",
        "- Meaning: The response touches the general topic but not the patient’s record.\n",
        "- Example:\n",
        "  Q: “When was my last blood test?”\n",
        "  A: “Blood tests are usually done annually.”\n",
        "  → Only generic information.\n",
        "\n",
        "3: MODERATELY RELEVANT\n",
        "- Meaning: The response partially answers or hints at relevant data but misses key specifics.\n",
        "- Example:\n",
        "  Q: “What medications am I currently taking?”\n",
        "  A: “You are prescribed metformin, but I’m not sure about your other medications.”\n",
        "  → Partial relevance.\n",
        "\n",
        "4: HIGHLY RELEVANT\n",
        "- Meaning: The response clearly addresses the question using mostly correct patient-specific data, minor omissions acceptable.\n",
        "- Example:\n",
        "  Q: “When was my last lab test?”\n",
        "  A: “Your most recent lab test was in March 2024 for blood glucose.”\n",
        "  → Very good relevance.\n",
        "\n",
        "5: PERFECTLY RELEVANT\n",
        "- Meaning: The response is direct, complete, and fully focused on the patient’s question and personal data.\n",
        "- Example:\n",
        "  Q: “What medications am I currently taking?”\n",
        "  A: “You are currently taking Metformin 500 mg twice daily and Lisinopril 10 mg once daily.”\n",
        "  → Excellent relevance.\n",
        "\n",
        "Now evaluate the following pair:\n",
        "\n",
        "User Question: {user_question}\n",
        "Portal Response: {portal_response}\n",
        "\n",
        "***Output Format***\n",
        "Provide your output strictly as a JSON object:\n",
        "- \"User Question\": \"{user_question}\",\n",
        "- \"Portal Response\": \"{portal_response}\",\n",
        "- \"Relevance Score\": <integer between 1 and 5>\n",
        "\n",
        "Do not include explanations, reasoning, or any text outside this JSON object.\n",
        "\"\"\"\n"
      ],
      "metadata": {
        "id": "R0BV5T2kcVKK"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_as_text = df.to_markdown(index=False)\n",
        "\n",
        "# Build the full Faithfulness evaluation prompt\n",
        "judge_prompt_F = f\"\"\"You are an expert medical data evaluator assessing the factual correctness of a patient-portal system's response.\n",
        "\n",
        "Your task is to provide a Faithfulness score (1–5) indicating how accurately the response reflects the factual information in the retrieved records.\n",
        "\n",
        "***Criterion Definition***\n",
        "FAITHFULNESS: The degree to which the response content is factually consistent with the evidence provided in the retrieved records below.\n",
        "Do NOT judge relevance or helpfulness — only whether the statements are supported by the retrieved data.\n",
        "\n",
        "***Score Definitions (with Domain-Relevant Examples)***\n",
        "\n",
        "1 — NOT FAITHFUL\n",
        "- Meaning: Mostly incorrect or hallucinated; contradicts the records.\n",
        "- Example Evidence (Medications):\n",
        "  | medication | dose  | freq |\n",
        "  |------------|-------|------|\n",
        "  | Metformin  | 500mg | BID  |\n",
        "- Example Response: \"You’re taking Metformin 500 mg BID and Atorvastatin 20 mg QD.\"\n",
        "- Why: Atorvastatin is not in evidence → contradiction.\n",
        "\n",
        "2 — SLIGHTLY FAITHFUL\n",
        "- Meaning: Some correct facts, but significant unsupported claims remain.\n",
        "- Example Evidence (Labs):\n",
        "  | test | date       | result |\n",
        "  |------|------------|--------|\n",
        "  | A1C  | 2024-03-10 | 6.9%   |\n",
        "- Example Response: \"Your latest A1C on 2024-03-10 was 6.9%, and your LDL was 85 mg/dL.\"\n",
        "- Why: A1C detail is correct; LDL is unsupported → major error persists.\n",
        "\n",
        "3 — MODERATELY FAITHFUL\n",
        "- Meaning: Mostly supported, but one or two factual inaccuracies (e.g., wrong dose/date).\n",
        "- Example Evidence (Medications):\n",
        "  | medication | dose | freq |\n",
        "  |------------|------|------|\n",
        "  | Lisinopril | 10mg | QD   |\n",
        "- Example Response: \"You take Lisinopril 5 mg once daily.\"\n",
        "- Why: Correct med and frequency; dose is wrong → partial mismatch.\n",
        "\n",
        "4 — HIGHLY FAITHFUL\n",
        "- Meaning: Essentially correct; only minor discrepancy/omission (e.g., missing a less salient detail).\n",
        "- Example Evidence (Appointments):\n",
        "  | type             | date       | status    |\n",
        "  |------------------|------------|-----------|\n",
        "  | Cardio follow-up | 2025-06-14 | completed |\n",
        "- Example Response: \"Your last cardiology follow-up was in June 2025.\"\n",
        "- Why: Month/year correct; missing exact day → minor omission.\n",
        "\n",
        "5 — PERFECTLY FAITHFUL\n",
        "- Meaning: Fully supported; no contradictions or unsupported claims.\n",
        "- Example Evidence (Medications):\n",
        "  | medication | dose  | freq |\n",
        "  |------------|-------|------|\n",
        "  | Metformin  | 500mg | BID  |\n",
        "  | Lisinopril | 10mg  | QD   |\n",
        "- Example Response: \"You are taking Metformin 500 mg twice daily and Lisinopril 10 mg once daily.\"\n",
        "- Why: Every stated fact matches the records exactly.\n",
        "\n",
        "***Retrieved Records***\n",
        "```markdown\n",
        "{df_as_text}\n",
        "Response to Evaluate\n",
        "{portal_response}\n",
        "Output Format\n",
        "Return ONLY the following JSON object (no extra text):\n",
        "\n",
        "{{\n",
        "\"User Question\": \"{user_question}\",\n",
        "\"Portal Response\": \"{portal_response}\",\n",
        "\"Faithfulness Score\": <integer between 1 and 5>\n",
        "}}\n",
        "\n",
        "Judging Rules\n",
        "\n",
        "Use ONLY the provided records for verification; do not infer or assume missing facts.\n",
        "Formatting differences (e.g., \"twice daily\" vs \"BID\") are acceptable if semantically identical.\n",
        "If no evidence supports a claimed fact, treat it as unsupported.\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "2YNzWKi5k6cw"
      },
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Build the Helpfulness evaluation prompt\n",
        "judge_prompt_H = f\"\"\"\n",
        "You are an expert medical communication evaluator. Judge how HELPFUL the patient-portal system's response is to the patient.\n",
        "\n",
        "Your task is to provide a Helpfulness score (1–5) indicating whether the response meaningfully helps the patient act on or understand their own medical record question.\n",
        "\n",
        "***Criterion Definition***\n",
        "HELPFULNESS: The degree to which the response is immediately useful to the patient—i.e., it answers the question clearly and provides actionable guidance (when appropriate), next steps, or pointers to where the patient can find the information in their portal. Do NOT judge factual correctness (that's Faithfulness) or topicality (that's Relevance).\n",
        "\n",
        "***Score Definitions (with Patient-Portal Examples)***\n",
        "\n",
        "1 — NOT HELPFUL\n",
        "- Meaning: Off-topic, evasive, or gives no usable guidance.\n",
        "- Example Q: \"When was my last cholesterol test?\"\n",
        "- Example A: \"Cholesterol is a type of fat in the blood.\"\n",
        "- Why: No answer, no steps.\n",
        "\n",
        "2 — SLIGHTLY HELPFUL\n",
        "- Meaning: Some topical info but still not actionable or patient-focused.\n",
        "- Example Q: \"What meds am I currently taking?\"\n",
        "- Example A: \"Medications are often used to manage chronic conditions.\"\n",
        "- Why: General info; provides no path to the patient’s own info.\n",
        "\n",
        "3 — MODERATELY HELPFUL\n",
        "- Meaning: Partially useful; gives a hint or partial answer but lacks clarity or next steps.\n",
        "- Example Q: \"Do I have any upcoming appointments?\"\n",
        "- Example A: \"You can check upcoming visits in the Appointments section.\"\n",
        "- Why: Direction is given, but no direct status or concrete steps (e.g., exact path).\n",
        "\n",
        "4 — HIGHLY HELPFUL\n",
        "- Meaning: Clear, patient-centered answer with minor omissions; includes concise steps or references.\n",
        "- Example Q: \"Where can I see my vaccine history?\"\n",
        "- Example A: \"Open **Health Records → Immunizations** to view your vaccine history. If you don’t see recent entries, message your care team from **Messages → New Message**.\"\n",
        "- Why: Concrete portal path and next step.\n",
        "\n",
        "5 — PERFECTLY HELPFUL\n",
        "- Meaning: Direct, concise answer tailored to the question, with clear steps and guardrails when appropriate.\n",
        "- Example Q: \"How can I refill my Metformin?\"\n",
        "- Example A: \"Go to **Medications → Metformin → Refill**. If 'Refill' isn’t available, use **Messages → Pharmacy Request** or call the number on your prescription label. If you’re out of doses today, contact your pharmacy for an emergency supply.\"\n",
        "- Why: Immediate action path, fallback, and safety guidance.\n",
        "\n",
        "***Judging Rules***\n",
        "- Focus ONLY on usefulness to the patient: clarity, directness, actionable steps, and appropriate guardrails.\n",
        "- Prefer concise, structured guidance (e.g., portal navigation paths, who to contact, what to click).\n",
        "- Do not penalize for not repeating data that belongs in the chart; penalize if it fails to guide the patient to it.\n",
        "- Don’t reward unnecessary medical theory/jargon if it doesn’t help the patient do something.\n",
        "- If the response can’t answer due to missing data, helpfulness increases when it explicitly states that and gives exact next steps to obtain it (e.g., where to look or whom to message).\n",
        "- Safety: Encourage contacting clinicians for urgent symptoms; do not judge medical accuracy here.\n",
        "\n",
        "***Input Pair to Evaluate***\n",
        "User Question:\n",
        "{user_question}\n",
        "\n",
        "Portal Response:\n",
        "{portal_response}\n",
        "\n",
        "***Output Format***\n",
        "Return ONLY the following JSON object (no extra text):\n",
        "\n",
        "{{\n",
        "  \"User Question\": \"{user_question}\",\n",
        "  \"Portal Response\": \"{portal_response}\",\n",
        "  \"Helpfulness Score\": <integer between 1 and 5>\n",
        "}}\n",
        "\"\"\"\n"
      ],
      "metadata": {
        "id": "EPgjeHfete8r"
      },
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# MedGemma-27B-text-it\n",
        "\n",
        "\n",
        "\n",
        "*   MedGemma-27B-text-it instruction tuned better accuracy as a judge than Mistral 7B\n",
        "*   QLoRA use on A100 40GB\n",
        "\n"
      ],
      "metadata": {
        "id": "fCgDU1kq5cjL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig\n",
        "from huggingface_hub import login # Import the login function\n",
        "\n",
        "# Log in to Hugging Face\n",
        "try:\n",
        "    from google.colab import userdata\n",
        "    hf_token = userdata.get('HF_TOKEN') # Assuming you have stored your HF token in Colab Secrets\n",
        "    if hf_token:\n",
        "        login(token=hf_token)\n",
        "    else:\n",
        "        print(\"Hugging Face token not found in Colab Secrets. Please add it as 'HF_TOKEN'.\")\n",
        "except Exception:\n",
        "    print(\"Could not retrieve Hugging Face token from Colab Secrets.\")\n",
        "    # Fallback to manual input if needed, but not recommended for security\n",
        "    # import getpass\n",
        "    # hf_token = getpass.getpass(\"Enter your Hugging Face token: \")\n",
        "    # login(token=hf_token)\n",
        "\n",
        "\n",
        "model_id = \"google/medgemma-27b-text-it\"  # or the exact HF ID you use\n",
        "\n",
        "bnb_cfg = BitsAndBytesConfig(load_in_4bit=True,\n",
        "                             bnb_4bit_quant_type=\"nf4\",\n",
        "                             bnb_4bit_compute_dtype=torch.bfloat16,\n",
        "                             bnb_4bit_use_double_quant=True)\n",
        "\n",
        "tok = AutoTokenizer.from_pretrained(model_id, use_fast=True)\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    model_id,\n",
        "    device_map=\"auto\",\n",
        "    quantization_config=bnb_cfg,\n",
        "    torch_dtype=torch.bfloat16\n",
        ")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66,
          "referenced_widgets": [
            "46e47345805e417ca4f3782b9dcdb327",
            "42b6a0d83c4d4ee1892fba444dc58ea1",
            "51b27227538e404dad2a2e6b061cf6ac",
            "195f81195f21411dbf4f218d1dfef17b",
            "de1e507d5d324a51867ab558c5323aa4",
            "795ec8bef88745a0843733b5a03246fd",
            "7a231ac36a3145b9b286d5aa04cce0ed",
            "64efd766516447fab775019f7a4b3372",
            "d867931fc8d64e08bbb6389da4a15f0a",
            "e337e1fa29fa4f66b10f956e3745dc81",
            "68641c77c3654a2cb4f4c553c63aa43f"
          ]
        },
        "id": "dpp6jqov5w7L",
        "outputId": "5338375c-2a7b-41c4-95b4-06e07a5c4d02"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "`torch_dtype` is deprecated! Use `dtype` instead!\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/11 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "46e47345805e417ca4f3782b9dcdb327"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def chat(prompt, max_new_tokens=256, temperature=0.0):\n",
        "    inputs = tok(prompt, return_tensors=\"pt\").to(model.device)\n",
        "\n",
        "    # --- The necessary fix is here: determine do_sample based on temperature ---\n",
        "    # When temperature is 0.0, you want greedy decoding (do_sample=False).\n",
        "    # Otherwise, you want sampling (do_sample=True).\n",
        "    do_sample_setting = temperature > 0.0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        out = model.generate(\n",
        "            **inputs,\n",
        "            max_new_tokens=max_new_tokens,\n",
        "            temperature=temperature,\n",
        "            # Pass the corrected setting to the model.generate function\n",
        "            do_sample=do_sample_setting\n",
        "        )\n",
        "    return tok.decode(out[0], skip_special_tokens=True)\n",
        "\n",
        "# Example: Run with greedy decoding (temperature=0.0)\n",
        "# response_greedy = chat(\"What is the primary treatment for strep throat?\", temperature=0.0)\n",
        "\n",
        "# Example: Run with sampling (temperature=0.7)\n",
        "# response_creative = chat(\"Write a short poem about a doctor's morning rounds.\", temperature=0.7)"
      ],
      "metadata": {
        "id": "6YVbbcrlNzZt"
      },
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "def create_payload(patient_id:str, user_q:str, k=5, max_tokens=1000, model=LLM_MODEL):\n",
        "    \"\"\"For a patient id, and a user question, returns\n",
        "    Sql, df, non-empathy-optimized summary, optimized summary, optimized score\n",
        "    returns a dict.\"\"\"\n",
        "    sql, rows = answer_patient_question(user_q, patient_id, k, max_tokens)\n",
        "    df = pd.DataFrame(rows)\n",
        "    non_optimized_response = summarize_df_with_llm(df, patient_id=patient_id, model=LLM_MODEL)\n",
        "\n",
        "    optimized_result = optimize_patient_response(\n",
        "          query=user_q,\n",
        "          data=df,\n",
        "          max_retries=3 # Will stop after 3 attempts, even if score < 4\n",
        "          )\n",
        "\n",
        "    optimized_emp_score = optimized_result['empathy_score']\n",
        "    optimized_response = optimized_result['response']\n",
        "\n",
        "    dict = {\n",
        "        \"sql\": sql,\n",
        "        \"df\" : df.to_markdown(),\n",
        "        \"non_opt_resp\": non_optimized_response,\n",
        "        \"opt_score\": optimized_emp_score,\n",
        "        \"opt_response\": optimized_response\n",
        "\n",
        "    }\n",
        "\n",
        "    return dict\n"
      ],
      "metadata": {
        "id": "Y99uRqWR_uNV"
      },
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#test\n",
        "patient_id = '0fca905f-391c-08d3-4b93-b53f69b9da53'\n",
        "user_q = 'which medication am I taking?'\n",
        "payload = create_payload(patient_id,user_q, model=LLM_MODEL)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pw33ZflGBltA",
        "outputId": "14a98d63-a292-4ece-9091-de48a67ced7c"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- STARTING OPTIMIZATION (Max Retries: 3) ---\n",
            "\n",
            "--- GENERATING RESPONSE (Retry: 0) ---\n",
            "\n",
            "--- EVALUATING RESPONSE ---\n",
            "-> Score: 5/5\n",
            "\n",
            "*** ROUTE: END (Score > 3) ***\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "payload.keys()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hUH-r49nfj2B",
        "outputId": "edb8c9c7-d32e-492e-da37-f36e7e7ef0a8"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['sql', 'df', 'non_opt_resp', 'opt_score', 'opt_response'])"
            ]
          },
          "metadata": {},
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "payload"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yzO-7xJgB-Ie",
        "outputId": "14031a2b-c815-4269-89ac-092f3d8b2c98"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'sql': 'SELECT DISTINCT ON (mr.patient_id, mr.med_name)\\n  mr.patient_id,\\n  mr.med_name AS medication,\\n  mr.dose,\\n  mr.route,\\n  mr.start_datetime,\\n  mr.end_datetime,\\n  mr.refills\\nFROM medication_requests mr\\nWHERE mr.patient_id = :patient_id\\n  AND (mr.end_datetime IS NULL OR mr.end_datetime >= NOW())\\nORDER BY mr.patient_id,\\n         mr.med_name,\\n         COALESCE(mr.end_datetime, mr.start_datetime) DESC NULLS LAST;',\n",
              " 'df': '|    | patient_id                           | medication                                                      |   dose | route   | start_datetime   | end_datetime   | refills   |\\n|---:|:-------------------------------------|:----------------------------------------------------------------|-------:|:--------|:-----------------|:---------------|:----------|\\n|  0 | 0fca905f-391c-08d3-4b93-b53f69b9da53 | Acetaminophen 325 MG Oral Tablet [Tylenol]                      |      1 |         |                  |                |           |\\n|  1 | 0fca905f-391c-08d3-4b93-b53f69b9da53 | Acetaminophen 325 MG / oxyCODONE Hydrochloride 5 MG Oral Tablet |      1 |         |                  |                |           |\\n|  2 | 0fca905f-391c-08d3-4b93-b53f69b9da53 | amLODIPine 2.5 MG Oral Tablet                                   |      1 |         |                  |                |           |\\n|  3 | 0fca905f-391c-08d3-4b93-b53f69b9da53 | Naproxen sodium 220 MG Oral Tablet                              |        |         |                  |                |           |\\n|  4 | 0fca905f-391c-08d3-4b93-b53f69b9da53 |                                                                 |        |         |                  |                |           |',\n",
              " 'non_opt_resp': 'The table shows medication records for patient ID 0fca905f-391c-08d3-4b93-b53f69b9da53, with five entries listed. All medications are oral tablets, including Acetaminophen, oxyCODONE, and amLODIPine, with doses specified for each except for Naproxen sodium, which has no dose listed. Notably, all entries lack start and end dates, as well as refill information, indicating a potential gap in treatment tracking. The table appears truncated, showing only 5 rows.',\n",
              " 'opt_score': 5,\n",
              " 'opt_response': \"I understand that it can be confusing to keep track of your medications, and I'm here to help you with that. Based on your records, you are currently taking the following medications:\\n\\n1. **Acetaminophen 325 MG Oral Tablet (Tylenol)**\\n2. **Acetaminophen 325 MG / OxyCODONE Hydrochloride 5 MG Oral Tablet**\\n3. **Amlodipine 2.5 MG Oral Tablet**\\n4. **Naproxen Sodium 220 MG Oral Tablet**\\n\\nIf you have any questions about these medications, such as their purposes or how to take them, please feel free to ask. It's important to ensure you feel comfortable and informed about your treatment.\"}"
            ]
          },
          "metadata": {},
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "user_question = user_q\n",
        "df = payload['df']\n",
        "portal_response = payload['opt_response']"
      ],
      "metadata": {
        "id": "QKEHxFaOCLAs"
      },
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ---------- Relevance ----------\n",
        "judge_prompt_R = \"\"\"\n",
        "You are an expert judge that evaluates the quality of a response provided by a patient question-answering LLM system to a patient's query.\n",
        "Your task is to provide a Relevance score (1–5) for how well the system's response answers the patient's question about their own medical history or records.\n",
        "\n",
        "***Criterion Definition***\n",
        "RELEVANCE: The degree to which the response directly and appropriately addresses the specific patient question about their medical record, history, medications, lab results, appointments, or related data.\n",
        "\n",
        "***Score Definitions and Examples***\n",
        "\n",
        "1: NOT RELEVANT\n",
        "- Meaning: The response does not relate to the patient's question.\n",
        "- Example:\n",
        "  Q: \"What medications am I currently taking?\"\n",
        "  A: \"You should eat a balanced diet.\"\n",
        "  → Not relevant.\n",
        "\n",
        "2: SLIGHTLY RELEVANT\n",
        "- Meaning: The response touches the general topic but not the patient's record.\n",
        "- Example:\n",
        "  Q: \"When was my last blood test?\"\n",
        "  A: \"Blood tests are usually done annually.\"\n",
        "  → Only generic information.\n",
        "\n",
        "3: MODERATELY RELEVANT\n",
        "- Meaning: The response partially answers or hints at relevant data but misses key specifics.\n",
        "- Example:\n",
        "  Q: \"What medications am I currently taking?\"\n",
        "  A: \"You are prescribed metformin, but I'm not sure about your other medications.\"\n",
        "  → Partial relevance.\n",
        "\n",
        "4: HIGHLY RELEVANT\n",
        "- Meaning: The response clearly addresses the question using mostly correct patient-specific data, minor omissions acceptable.\n",
        "- Example:\n",
        "  Q: \"When was my last lab test?\"\n",
        "  A: \"Your most recent lab test was in March 2024 for blood glucose.\"\n",
        "  → Very good relevance.\n",
        "\n",
        "5: PERFECTLY RELEVANT\n",
        "- Meaning: The response is direct, complete, and fully focused on the patient's question and personal data.\n",
        "- Example:\n",
        "  Q: \"What medications am I currently taking?\"\n",
        "  A: \"You are currently taking Metformin 500 mg twice daily and Lisinopril 10 mg once daily.\"\n",
        "  → Excellent relevance.\n",
        "\n",
        "Now evaluate the following pair:\n",
        "\n",
        "User Question: {user_question}\n",
        "Portal Response: {portal_response}\n",
        "\n",
        "***Output Format***\n",
        "Provide your output strictly as a JSON object:\n",
        "\n",
        "{{\n",
        "  \"User Question\": \"{user_question}\",\n",
        "  \"Relevance Score\": <integer between 1 and 5>\n",
        "}}\n",
        "\n",
        "ONLY output the JSON object. Ensure all string values are on a single line and properly escaped.\n",
        "\n",
        "Do not include explanations, reasoning, or any text outside this JSON object.\n",
        "\"\"\"\n",
        "\n",
        "# ---------- Faithfulness ----------\n",
        "judge_prompt_F = \"\"\"\n",
        "You are an expert medical data evaluator assessing the factual correctness of a patient-portal system's response.\n",
        "\n",
        "Your task is to provide a Faithfulness score (1–5) indicating how accurately the response reflects the factual information in the retrieved records.\n",
        "\n",
        "***Criterion Definition***\n",
        "FAITHFULNESS: The degree to which the response content is factually consistent with the evidence provided in the retrieved records below.\n",
        "Do NOT judge relevance or helpfulness — only whether the statements are supported by the retrieved data.\n",
        "\n",
        "***Score Definitions (with Domain-Relevant Examples)***\n",
        "\n",
        "1 — NOT FAITHFUL\n",
        "- Meaning: Mostly incorrect or hallucinated; contradicts the records.\n",
        "- Example Evidence (Medications):\n",
        "  | medication | dose  | freq |\n",
        "  |------------|-------|------|\n",
        "  | Metformin  | 500mg | BID  |\n",
        "- Example Response: \"You’re taking Metformin 500 mg BID and Atorvastatin 20 mg QD.\"\n",
        "- Why: Atorvastatin is not in evidence → contradiction.\n",
        "\n",
        "2 — SLIGHTLY FAITHFUL\n",
        "- Meaning: Some correct facts, but significant unsupported claims remain.\n",
        "- Example Evidence (Labs):\n",
        "  | test | date       | result |\n",
        "  |------|------------|--------|\n",
        "  | A1C  | 2024-03-10 | 6.9%   |\n",
        "- Example Response: \"Your latest A1C on 2024-03-10 was 6.9%, and your LDL was 85 mg/dL.\"\n",
        "- Why: A1C detail is correct; LDL is unsupported → major error persists.\n",
        "\n",
        "3 — MODERATELY FAITHFUL\n",
        "- Meaning: Mostly supported, but one or two factual inaccuracies (e.g., wrong dose/date).\n",
        "- Example Evidence (Medications):\n",
        "  | medication | dose | freq |\n",
        "  |------------|------|------|\n",
        "  | Lisinopril | 10mg | QD   |\n",
        "- Example Response: \"You take Lisinopril 5 mg once daily.\"\n",
        "- Why: Correct med and frequency; dose is wrong → partial mismatch.\n",
        "\n",
        "4 — HIGHLY FAITHFUL\n",
        "- Meaning: Essentially correct; only minor discrepancy/omission (e.g., missing a less salient detail).\n",
        "- Example Evidence (Appointments):\n",
        "  | type             | date       | status    |\n",
        "  |------------------|------------|-----------|\n",
        "  | Cardio follow-up | 2025-06-14 | completed |\n",
        "- Example Response: \"Your last cardiology follow-up was in June 2025.\"\n",
        "- Why: Month/year correct; missing exact day → minor omission.\n",
        "\n",
        "5 — PERFECTLY FAITHFUL\n",
        "- Meaning: Fully supported; no contradictions or unsupported claims.\n",
        "- Example Evidence (Medications):\n",
        "  | medication | dose  | freq |\n",
        "  |------------|-------|------|\n",
        "  | Metformin  | 500mg | BID  |\n",
        "  | Lisinopril | 10mg  | QD   |\n",
        "- Example Response: \"You are taking Metformin 500 mg twice daily and Lisinopril 10 mg once daily.\"\n",
        "- Why: Every stated fact matches the records exactly.\n",
        "\n",
        "***Retrieved Records***\n",
        "```markdown\n",
        "{df_as_text}\n",
        "Response to Evaluate\n",
        "{portal_response}\n",
        "Output Format\n",
        "Return ONLY the following JSON object (no extra text):\n",
        "\n",
        "{{\n",
        "\"User Question\": \"{user_question}\",\n",
        "\"Faithfulness Score\": <integer between 1 and 5>\n",
        "}}\n",
        "\n",
        "ONLY output the JSON object. Ensure all string values are on a single line and properly escaped.\n",
        "\n",
        "Judging Rules\n",
        "\n",
        "Use ONLY the provided records for verification; do not infer or assume missing facts.\n",
        "Formatting differences (e.g., \"twice daily\" vs \"BID\") are acceptable if semantically identical.\n",
        "If no evidence supports a claimed fact, treat it as unsupported.\n",
        "\"\"\"\n",
        "#---------- Helpfulness ----------\n",
        "judge_prompt_H = \"\"\"\n",
        "You are an expert medical communication evaluator. Judge how HELPFUL the patient-portal system's response is to the patient.\n",
        "Your task is to provide a Helpfulness score (1–5) indicating whether the response meaningfully helps the patient act on or understand their own medical record question.\n",
        "\n",
        "Criterion Definition\n",
        "HELPFULNESS: The degree to which the response is immediately useful to the patient—i.e., it answers the question clearly and provides actionable guidance (when appropriate), next steps, or pointers to where the patient can find the information in their portal. Do NOT judge factual correctness (that's Faithfulness) or topicality (that's Relevance).\n",
        "\n",
        "Score Definitions (with Patient-Portal Examples)\n",
        "\n",
        "1 — NOT HELPFUL\n",
        "\n",
        "Meaning: Off-topic, evasive, or gives no usable guidance.\n",
        "Example Q: \"When was my last cholesterol test?\"\n",
        "Example A: \"Cholesterol is a type of fat in the blood.\"\n",
        "Why: No answer, no steps.\n",
        "2 — SLIGHTLY HELPFUL\n",
        "Meaning: Some topical info but still not actionable or patient-focused.\n",
        "Example Q: \"What meds am I currently taking?\"\n",
        "Example A: \"Medications are often used to manage chronic conditions.\"\n",
        "Why: General info; provides no path to the patient's own info.\n",
        "3 — MODERATELY HELPFUL\n",
        "Meaning: Partially useful; gives a hint or partial answer but lacks clarity or next steps.\n",
        "Example Q: \"Do I have any upcoming appointments?\"\n",
        "Example A: \"You can check upcoming visits in the Appointments section.\"\n",
        "Why: Direction is given, but no direct status or concrete steps (e.g., exact path).\n",
        "4 — HIGHLY HELPFUL\n",
        "Meaning: Clear, patient-centered answer with minor omissions; includes concise steps or references.\n",
        "Example Q: \"Where can I see my vaccine history?\"\n",
        "Example A: \"Open Health Records → Immunizations to view your vaccine history. If you don't see recent entries, message your care team from Messages → New Message.\"\n",
        "Why: Concrete portal path and next step.\n",
        "5 — PERFECTLY HELPFUL\n",
        "Meaning: Direct, concise answer tailored to the question, with clear steps and guardrails when appropriate.\n",
        "Example Q: \"How can I refill my Metformin?\"\n",
        "Example A: \"Go to Medications → Metformin → Refill. If 'Refill' isn't available, use Messages → Pharmacy Request or call the number on your prescription label. If you're out of doses today, contact your pharmacy for an emergency supply.\"\n",
        "Why: Immediate action path, fallback, and safety guidance.\n",
        "Judging Rules\n",
        "Focus ONLY on usefulness to the patient: clarity, directness, actionable steps, and appropriate guardrails.\n",
        "Prefer concise, structured guidance (e.g., portal navigation paths, who to contact, what to click).\n",
        "Do not penalize for not repeating data that belongs in the chart; penalize if it fails to guide the patient to it.\n",
        "Don't reward unnecessary medical theory/jargon if it doesn't help the patient do something.\n",
        "If the response can't answer due to missing data, helpfulness increases when it explicitly states that and gives exact next steps to obtain it (e.g., where to look or whom to message).\n",
        "Safety: Encourage contacting clinicians for urgent symptoms; do not judge medical accuracy here.\n",
        "Input Pair to Evaluate\n",
        "User Question:\n",
        "{user_question}\n",
        "Portal Response:\n",
        "{portal_response}\n",
        "\n",
        "Output Format\n",
        "Return ONLY the following JSON object (no extra text):\n",
        "\n",
        "{{\n",
        "\"User Question\": \"{user_question}\",\n",
        "\"Helpfulness Score\": <integer between 1 and 5>\n",
        "}}\n",
        "\n",
        "ONLY output the JSON object. Ensure all string values are on a single line and properly escaped.\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "zaNu7Z7uC4hQ"
      },
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Run medGemma\n",
        "\n",
        "import json\n",
        "import re\n",
        "\n",
        "import json\n",
        "import re\n",
        "\n",
        "def safe_json(s: str) -> dict:\n",
        "    \"\"\"\n",
        "    Safely extracts and parses a JSON object from an LLM's string output,\n",
        "    handling common control character errors, isolation issues, and syntax errors.\n",
        "    \"\"\"\n",
        "    s = s.strip()\n",
        "\n",
        "    # 1. Escape unescaped control characters.\n",
        "    # We escape newlines, tabs, and carriage returns.\n",
        "    s = s.replace('\\n', '\\\\n').replace('\\t', '\\\\t').replace('\\r', '\\\\r')\n",
        "\n",
        "    # 2. Use a more targeted regex to find the JSON block.\n",
        "    # This specifically looks for the object structure.\n",
        "    # re.DOTALL (re.S) ensures '.' matches newlines inside the object.\n",
        "    m = re.search(r\"(\\{.*\\}|\\[.*\\])\", s, re.DOTALL)\n",
        "\n",
        "    if m:\n",
        "        json_str = m.group(0)\n",
        "\n",
        "        # 3. CRITICAL FIX: Replace unescaped single quotes with double quotes.\n",
        "        # This solves the most common LLM syntax error: {'key': 'value'} vs {\"key\": \"value\"}\n",
        "        # This uses an aggressive replacement which works for simple strings, but fails on complex nested JSON where\n",
        "        # a single quote might be a valid character. The most robust solution is often a custom JSON library like `json5`.\n",
        "        json_str = json_str.replace(\"'\", '\"')\n",
        "\n",
        "        try:\n",
        "            # 4. Attempt to load the cleaned and isolated JSON string\n",
        "            return json.loads(json_str)\n",
        "        except json.JSONDecodeError as e:\n",
        "            # If standard parsing still fails, fall back to logging the error\n",
        "            return {\"raw\": s, \"error\": str(e)}\n",
        "    else:\n",
        "        # 5. No JSON structure found\n",
        "        return {\"raw\": s, \"error\": \"No JSON object found.\"}\n",
        "\n",
        "def run_judge_prompts(user_question, portal_response, df_as_text):\n",
        "    \"\"\"Run Relevance, Faithfulness, and Helpfulness prompts on MedGemma.\"\"\"\n",
        "\n",
        "    # ---- PROMPT 1: Relevance ----\n",
        "    prompt_R = judge_prompt_R.format(user_question=user_question,\n",
        "                                     portal_response=portal_response)\n",
        "    reply_R = chat(prompt_R)\n",
        "\n",
        "    # ---- PROMPT 2: Faithfulness ----\n",
        "    prompt_F = judge_prompt_F.format(user_question=user_question,\n",
        "                                     portal_response=portal_response,\n",
        "                                     df_as_text=df_as_text)\n",
        "    reply_F = chat(prompt_F)\n",
        "\n",
        "    # ---- PROMPT 3: Helpfulness ----\n",
        "    prompt_H = judge_prompt_H.format(user_question=user_question,\n",
        "                                     portal_response=portal_response)\n",
        "    reply_H = chat(prompt_H)\n",
        "\n",
        "    # Helper to extract JSON safely\n",
        "\n",
        "    result = {\n",
        "        \"Relevance\": safe_json(reply_R),\n",
        "        \"Faithfulness\": safe_json(reply_F),\n",
        "        \"Helpfulness\": safe_json(reply_H)\n",
        "    }\n",
        "    return result\n"
      ],
      "metadata": {
        "id": "RdoRm8l3DCMd"
      },
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Run MedGemma"
      ],
      "metadata": {
        "id": "hnFrrKwbFUFr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "patient_id = '0fca905f-391c-08d3-4b93-b53f69b9da53'\n",
        "user_q = 'which medication am I taking?'\n",
        "payload = create_payload(patient_id,user_q, model=LLM_MODEL)\n",
        "user_question = user_q\n",
        "df = payload['df']\n",
        "portal_response = payload['opt_response']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2iqAPNW9FRgA",
        "outputId": "4008bd70-a808-4c5d-c216-0fe42aa9ddb3"
      },
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- STARTING OPTIMIZATION (Max Retries: 3) ---\n",
            "\n",
            "--- GENERATING RESPONSE (Retry: 0) ---\n",
            "\n",
            "--- EVALUATING RESPONSE ---\n",
            "-> Score: 5/5\n",
            "\n",
            "*** ROUTE: END (Score > 3) ***\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "payload.keys()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kS2SXEVf4kFY",
        "outputId": "c6e6a078-4cba-447a-8e1b-4fc28693566e"
      },
      "execution_count": 132,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['sql', 'df', 'non_opt_resp', 'opt_score', 'opt_response'])"
            ]
          },
          "metadata": {},
          "execution_count": 132
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rfh_responses = run_judge_prompts(user_question, portal_response, df_as_text=df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tioC_ea6FtFa",
        "outputId": "5e766d3a-0b0e-4413-d09a-71aafcddf848"
      },
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Setting `pad_token_id` to `eos_token_id`:1 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:1 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:1 for open-end generation.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rfh_responses.keys()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oP1GWYiXcP0Y",
        "outputId": "14772c9d-e2a9-46ab-ed57-e95f29bc1045"
      },
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['Relevance', 'Faithfulness', 'Helpfulness'])"
            ]
          },
          "metadata": {},
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rfh_responses['Relevance']['error']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "B527KQxXckvF",
        "outputId": "f5b7537a-e2b8-44d7-fc68-2e982675e51e"
      },
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Expecting property name enclosed in double quotes: line 1 column 2 (char 1)'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 83
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rfh_responses['Relevance']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JkCrzLx0iV6b",
        "outputId": "d74fa963-6e6f-4af5-8b3f-176a81aa3d07"
      },
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'raw': 'You are an expert judge that evaluates the quality of a response provided by a patient question-answering LLM system to a patient\\'s query.\\\\nYour task is to provide a Relevance score (1–5) for how well the system\\'s response answers the patient\\'s question about their own medical history or records.\\\\n\\\\n***Criterion Definition***\\\\nRELEVANCE: The degree to which the response directly and appropriately addresses the specific patient question about their medical record, history, medications, lab results, appointments, or related data.\\\\n\\\\n***Score Definitions and Examples***\\\\n\\\\n1: NOT RELEVANT\\\\n- Meaning: The response does not relate to the patient\\'s question.\\\\n- Example:\\\\n  Q: \"What medications am I currently taking?\"\\\\n  A: \"You should eat a balanced diet.\"\\\\n  → Not relevant.\\\\n\\\\n2: SLIGHTLY RELEVANT\\\\n- Meaning: The response touches the general topic but not the patient\\'s record.\\\\n- Example:\\\\n  Q: \"When was my last blood test?\"\\\\n  A: \"Blood tests are usually done annually.\"\\\\n  → Only generic information.\\\\n\\\\n3: MODERATELY RELEVANT\\\\n- Meaning: The response partially answers or hints at relevant data but misses key specifics.\\\\n- Example:\\\\n  Q: \"What medications am I currently taking?\"\\\\n  A: \"You are prescribed metformin, but I\\'m not sure about your other medications.\"\\\\n  → Partial relevance.\\\\n\\\\n4: HIGHLY RELEVANT\\\\n- Meaning: The response clearly addresses the question using mostly correct patient-specific data, minor omissions acceptable.\\\\n- Example:\\\\n  Q: \"When was my last lab test?\"\\\\n  A: \"Your most recent lab test was in March 2024 for blood glucose.\"\\\\n  → Very good relevance.\\\\n\\\\n5: PERFECTLY RELEVANT\\\\n- Meaning: The response is direct, complete, and fully focused on the patient\\'s question and personal data.\\\\n- Example:\\\\n  Q: \"What medications am I currently taking?\"\\\\n  A: \"You are currently taking Metformin 500 mg twice daily and Lisinopril 10 mg once daily.\"\\\\n  → Excellent relevance.\\\\n\\\\nNow evaluate the following pair:\\\\n\\\\nUser Question: which medication am I taking?\\\\nPortal Response: I understand that it can be confusing to keep track of your medications, and I\\'m here to help you with that. Based on your records, you are currently taking the following medications:\\\\n\\\\n1. **Acetaminophen 325 MG Oral Tablet (Tylenol)**\\\\n2. **Acetaminophen 325 MG / OxyCODONE Hydrochloride 5 MG Oral Tablet**\\\\n3. **Amlodipine 2.5 MG Oral Tablet**\\\\n4. **Naproxen Sodium 220 MG Oral Tablet**\\\\n\\\\nIf you have any questions about these medications, such as their purposes or how to take them, please feel free to ask. It\\'s important to ensure you feel comfortable and informed about your treatment.\\\\n\\\\n***Output Format***\\\\nProvide your output strictly as a JSON object:\\\\n\\\\n{\\\\n  \"User Question\": \"which medication am I taking?\",\\\\n  \"Relevance Score\": <integer between 1 and 5>\\\\n}\\\\n\\\\nONLY output the JSON object. Ensure all string values are on a single line and properly escaped.\\\\n\\\\nDo not include explanations, reasoning, or any text outside this JSON object.\\\\n```json\\\\n{\\\\n  \"User Question\": \"which medication am I taking?\",\\\\n  \"Relevance Score\": 5\\\\n}\\\\n```',\n",
              " 'error': 'Expecting property name enclosed in double quotes: line 1 column 2 (char 1)'}"
            ]
          },
          "metadata": {},
          "execution_count": 84
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rfh_responses.keys()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s1g_3h8AfOjL",
        "outputId": "40d34277-3126-414f-c854-89365737c1e1"
      },
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['Relevance', 'Faithfulness', 'Helpfulness'])"
            ]
          },
          "metadata": {},
          "execution_count": 85
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(rfh_responses['Relevance']['raw'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AeUn8TtekRPg",
        "outputId": "a37ee41a-f7ca-44c0-c1b2-ca7dc92aee26"
      },
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "You are an expert judge that evaluates the quality of a response provided by a patient question-answering LLM system to a patient's query.\\nYour task is to provide a Relevance score (1–5) for how well the system's response answers the patient's question about their own medical history or records.\\n\\n***Criterion Definition***\\nRELEVANCE: The degree to which the response directly and appropriately addresses the specific patient question about their medical record, history, medications, lab results, appointments, or related data.\\n\\n***Score Definitions and Examples***\\n\\n1: NOT RELEVANT\\n- Meaning: The response does not relate to the patient's question.\\n- Example:\\n  Q: \"What medications am I currently taking?\"\\n  A: \"You should eat a balanced diet.\"\\n  → Not relevant.\\n\\n2: SLIGHTLY RELEVANT\\n- Meaning: The response touches the general topic but not the patient's record.\\n- Example:\\n  Q: \"When was my last blood test?\"\\n  A: \"Blood tests are usually done annually.\"\\n  → Only generic information.\\n\\n3: MODERATELY RELEVANT\\n- Meaning: The response partially answers or hints at relevant data but misses key specifics.\\n- Example:\\n  Q: \"What medications am I currently taking?\"\\n  A: \"You are prescribed metformin, but I'm not sure about your other medications.\"\\n  → Partial relevance.\\n\\n4: HIGHLY RELEVANT\\n- Meaning: The response clearly addresses the question using mostly correct patient-specific data, minor omissions acceptable.\\n- Example:\\n  Q: \"When was my last lab test?\"\\n  A: \"Your most recent lab test was in March 2024 for blood glucose.\"\\n  → Very good relevance.\\n\\n5: PERFECTLY RELEVANT\\n- Meaning: The response is direct, complete, and fully focused on the patient's question and personal data.\\n- Example:\\n  Q: \"What medications am I currently taking?\"\\n  A: \"You are currently taking Metformin 500 mg twice daily and Lisinopril 10 mg once daily.\"\\n  → Excellent relevance.\\n\\nNow evaluate the following pair:\\n\\nUser Question: which medication am I taking?\\nPortal Response: I understand that it can be confusing to keep track of your medications, and I'm here to help you with that. Based on your records, you are currently taking the following medications:\\n\\n1. **Acetaminophen 325 MG Oral Tablet (Tylenol)**\\n2. **Acetaminophen 325 MG / OxyCODONE Hydrochloride 5 MG Oral Tablet**\\n3. **Amlodipine 2.5 MG Oral Tablet**\\n4. **Naproxen Sodium 220 MG Oral Tablet**\\n\\nIf you have any questions about these medications, such as their purposes or how to take them, please feel free to ask. It's important to ensure you feel comfortable and informed about your treatment.\\n\\n***Output Format***\\nProvide your output strictly as a JSON object:\\n\\n{\\n  \"User Question\": \"which medication am I taking?\",\\n  \"Relevance Score\": <integer between 1 and 5>\\n}\\n\\nONLY output the JSON object. Ensure all string values are on a single line and properly escaped.\\n\\nDo not include explanations, reasoning, or any text outside this JSON object.\\n```json\\n{\\n  \"User Question\": \"which medication am I taking?\",\\n  \"Relevance Score\": 5\\n}\\n```\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "s = rfh_responses['Relevance']['raw']\n"
      ],
      "metadata": {
        "id": "6lXDCsNil3ls"
      },
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pprint\n",
        "\n",
        "pprint.pprint(rfh_responses['Relevance'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "guRrSKDIieAg",
        "outputId": "e34f2a3f-c9f9-47ad-f14f-b599bc1846a5"
      },
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'error': 'Expecting property name enclosed in double quotes: line 1 column 2 '\n",
            "          '(char 1)',\n",
            " 'raw': 'You are an expert judge that evaluates the quality of a response '\n",
            "        \"provided by a patient question-answering LLM system to a patient's \"\n",
            "        'query.\\\\nYour task is to provide a Relevance score (1–5) for how well '\n",
            "        \"the system's response answers the patient's question about their own \"\n",
            "        'medical history or records.\\\\n\\\\n***Criterion '\n",
            "        'Definition***\\\\nRELEVANCE: The degree to which the response directly '\n",
            "        'and appropriately addresses the specific patient question about their '\n",
            "        'medical record, history, medications, lab results, appointments, or '\n",
            "        'related data.\\\\n\\\\n***Score Definitions and Examples***\\\\n\\\\n1: NOT '\n",
            "        \"RELEVANT\\\\n- Meaning: The response does not relate to the patient's \"\n",
            "        'question.\\\\n- Example:\\\\n  Q: \"What medications am I currently '\n",
            "        'taking?\"\\\\n  A: \"You should eat a balanced diet.\"\\\\n  → Not '\n",
            "        'relevant.\\\\n\\\\n2: SLIGHTLY RELEVANT\\\\n- Meaning: The response touches '\n",
            "        \"the general topic but not the patient's record.\\\\n- Example:\\\\n  Q: \"\n",
            "        '\"When was my last blood test?\"\\\\n  A: \"Blood tests are usually done '\n",
            "        'annually.\"\\\\n  → Only generic information.\\\\n\\\\n3: MODERATELY '\n",
            "        'RELEVANT\\\\n- Meaning: The response partially answers or hints at '\n",
            "        'relevant data but misses key specifics.\\\\n- Example:\\\\n  Q: \"What '\n",
            "        'medications am I currently taking?\"\\\\n  A: \"You are prescribed '\n",
            "        'metformin, but I\\'m not sure about your other medications.\"\\\\n  → '\n",
            "        'Partial relevance.\\\\n\\\\n4: HIGHLY RELEVANT\\\\n- Meaning: The response '\n",
            "        'clearly addresses the question using mostly correct patient-specific '\n",
            "        'data, minor omissions acceptable.\\\\n- Example:\\\\n  Q: \"When was my '\n",
            "        'last lab test?\"\\\\n  A: \"Your most recent lab test was in March 2024 '\n",
            "        'for blood glucose.\"\\\\n  → Very good relevance.\\\\n\\\\n5: PERFECTLY '\n",
            "        'RELEVANT\\\\n- Meaning: The response is direct, complete, and fully '\n",
            "        \"focused on the patient's question and personal data.\\\\n- Example:\\\\n  \"\n",
            "        'Q: \"What medications am I currently taking?\"\\\\n  A: \"You are '\n",
            "        'currently taking Metformin 500 mg twice daily and Lisinopril 10 mg '\n",
            "        'once daily.\"\\\\n  → Excellent relevance.\\\\n\\\\nNow evaluate the '\n",
            "        'following pair:\\\\n\\\\nUser Question: which medication am I '\n",
            "        'taking?\\\\nPortal Response: I understand that it can be confusing to '\n",
            "        \"keep track of your medications, and I'm here to help you with that. \"\n",
            "        'Based on your records, you are currently taking the following '\n",
            "        'medications:\\\\n\\\\n1. **Acetaminophen 325 MG Oral Tablet '\n",
            "        '(Tylenol)**\\\\n2. **Acetaminophen 325 MG / OxyCODONE Hydrochloride 5 '\n",
            "        'MG Oral Tablet**\\\\n3. **Amlodipine 2.5 MG Oral Tablet**\\\\n4. '\n",
            "        '**Naproxen Sodium 220 MG Oral Tablet**\\\\n\\\\nIf you have any questions '\n",
            "        'about these medications, such as their purposes or how to take them, '\n",
            "        \"please feel free to ask. It's important to ensure you feel \"\n",
            "        'comfortable and informed about your treatment.\\\\n\\\\n***Output '\n",
            "        'Format***\\\\nProvide your output strictly as a JSON object:\\\\n\\\\n{\\\\n  '\n",
            "        '\"User Question\": \"which medication am I taking?\",\\\\n  \"Relevance '\n",
            "        'Score\": <integer between 1 and 5>\\\\n}\\\\n\\\\nONLY output the JSON '\n",
            "        'object. Ensure all string values are on a single line and properly '\n",
            "        'escaped.\\\\n\\\\nDo not include explanations, reasoning, or any text '\n",
            "        'outside this JSON object.\\\\n```json\\\\n{\\\\n  \"User Question\": \"which '\n",
            "        'medication am I taking?\",\\\\n  \"Relevance Score\": 5\\\\n}\\\\n```'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# MedGemma did not follow JSON output instructions, so we piped its reponse to 4 o mini to generate a clear output"
      ],
      "metadata": {
        "id": "Uey9tA6jo4J_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pydantic import BaseModel, Field\n",
        "from typing import Literal\n",
        "\n",
        "class JudgeOutput_R(BaseModel):\n",
        "    \"\"\"The final, clean, structured output from the evaluation process.\"\"\"\n",
        "    user_question: str = Field(description=\"The original question from the patient.\")\n",
        "    portal_response: str = Field(description=\"The full response provided by the patient-facing system.\")\n",
        "    relevance_score: Literal[1, 2, 3, 4, 5] = Field(description=\"The final Relevance score (1-5) based on the criteria provided in the prompt.\")\n",
        "\n",
        "class JudgeOutput_F(BaseModel):\n",
        "    \"\"\"The final, clean, structured output from the evaluation process.\"\"\"\n",
        "    user_question: str = Field(description=\"The original question from the patient.\")\n",
        "    portal_response: str = Field(description=\"The full response provided by the patient-facing system.\")\n",
        "    faithfulness_score: Literal[1, 2, 3, 4, 5] = Field(description=\"The final Faithfulness score (1-5) based on the criteria provided in the prompt.\")\n",
        "\n",
        "class JudgeOutput_H(BaseModel):\n",
        "    \"\"\"The final, clean, structured output from the evaluation process.\"\"\"\n",
        "    user_question: str = Field(description=\"The original question from the patient.\")\n",
        "    portal_response: str = Field(description=\"The full response provided by the patient-facing system.\")\n",
        "    helpfulness_score: Literal[1, 2, 3, 4, 5] = Field(description=\"The final Helpfulness score (1-5) based on the criteria provided in the prompt.\")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "i7ZxxtfvpC7Q"
      },
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_outputJSON_R(rfh_responses, model, JudgeOutput_R):\n",
        "  \"\"\"returns a well formatted json response (user_question, portal_response, relevance score)\n",
        "  for 'Relevance' key in unprocessed rfh_responses. Uses model = gpt-40-mini\n",
        "  Expects Pydantic schema JudgeOutput_R\n",
        "  \"\"\"\n",
        "\n",
        "  # Get the specific formatting instructions for GPT-4o mini\n",
        "  parser_R = PydanticOutputParser(pydantic_object=JudgeOutput_R)\n",
        "  format_instructions_R = parser_R.get_format_instructions()\n",
        "\n",
        "  correction_prompt_R = ChatPromptTemplate.from_messages([\n",
        "      (\"system\",\n",
        "      \"You are a strict JSON formatter. Your task is to extract the 'User Question', 'Portal Response', and the 'Relevance Score' from the RAW TEXT provided below, and reformat it STRICTLY according to the given JSON schema. Output your response as a JSON object.\"),\n",
        "      (\"human\",\n",
        "      \"RAW TEXT (May contain errors, markdown, or extra text):\\n---\\n{raw_medgemma_output}\\n---\\n\\n{format_instructions_R}\") # <-- Still requires this variable\n",
        "  ])\n",
        "\n",
        "  correction_prompt_R_fixed = correction_prompt_R.partial(\n",
        "      format_instructions_R=format_instructions_R\n",
        "  )\n",
        "  correction_chain_R = correction_prompt_R_fixed | model | parser_R\n",
        "\n",
        "  reply_R = rfh_responses['Relevance']['raw']\n",
        "  validated_output_R = correction_chain_R.invoke({\"raw_medgemma_output\": reply_R})\n",
        "  json_string_R = validated_output_R.model_dump_json(indent=4)\n",
        "\n",
        "  return json_string_R\n",
        "\n",
        "\n",
        "def get_outputJSON_F(rfh_responses, model, JudgeOutput_F):\n",
        "  \"\"\"returns a well formatted json response (user_question, portal_response, faithfulness score)\n",
        "  for 'Faithfulness' key in unprocessed rfh_responses. Uses model = gpt-40-mini\n",
        "  Expects Pydantic schema JudgeOutput_F\n",
        "  \"\"\"\n",
        "\n",
        "  # Get the specific formatting instructions for GPT-4o mini\n",
        "  # 2. Get the specific formatting instructions for GPT-4o mini\n",
        "  parser_F = PydanticOutputParser(pydantic_object=JudgeOutput_F)\n",
        "  format_instructions_F = parser_F.get_format_instructions()\n",
        "\n",
        "  correction_prompt_F = ChatPromptTemplate.from_messages([\n",
        "      (\"system\",\n",
        "      \"You are a strict JSON formatter. Your task is to extract the 'User Question', 'Portal Response', and the 'Faithfulness Score' from the RAW TEXT provided below, and reformat it STRICTLY according to the given JSON schema. Output your response as a JSON object.\"),\n",
        "      (\"human\",\n",
        "      \"RAW TEXT (May contain errors, markdown, or extra text):\\n---\\n{raw_medgemma_output}\\n---\\n\\n{format_instructions_F}\") # <-- Still requires this variable\n",
        "  ])\n",
        "\n",
        "  correction_prompt_F_fixed = correction_prompt_F.partial(\n",
        "      format_instructions_F=format_instructions_F\n",
        "  )\n",
        "  correction_chain_F = correction_prompt_F_fixed | model | parser_F\n",
        "\n",
        "  reply_F = rfh_responses['Faithfulness']['raw']\n",
        "  validated_output_F = correction_chain_F.invoke({\"raw_medgemma_output\": reply_F})\n",
        "  json_string_F = validated_output_F.model_dump_json(indent=4)\n",
        "\n",
        "  return json_string_F\n",
        "\n",
        "\n",
        "def get_outputJSON_H(rfh_responses, model, JudgeOutput_H):\n",
        "  \"\"\"returns a well formatted json response (user_question, portal_response, helpfulness score)\n",
        "  for 'Helpfulness' key in unprocessed rfh_responses. Uses model = gpt-40-mini\n",
        "  Expects Pydantic schema JudgeOutput_H\n",
        "  \"\"\"\n",
        "\n",
        "  # Get the specific formatting instructions for GPT-4o mini\n",
        "  # 2. Get the specific formatting instructions for GPT-4o mini\n",
        "  # 2. Get the specific formatting instructions for GPT-4o mini\n",
        "  parser_H = PydanticOutputParser(pydantic_object=JudgeOutput_H)\n",
        "  format_instructions_H = parser_H.get_format_instructions()\n",
        "\n",
        "  correction_prompt_H = ChatPromptTemplate.from_messages([\n",
        "      (\"system\",\n",
        "      \"You are a strict JSON formatter. Your task is to extract the 'User Question', 'Portal Response', and the 'Helpfulness Score' from the RAW TEXT provided below, and reformat it STRICTLY according to the given JSON schema. Output your response as a JSON object.\"),\n",
        "      (\"human\",\n",
        "      \"RAW TEXT (May contain errors, markdown, or extra text):\\n---\\n{raw_medgemma_output}\\n---\\n\\n{format_instructions_H}\") # <-- Still requires this variable\n",
        "  ])\n",
        "\n",
        "  correction_prompt_H_fixed = correction_prompt_F.partial(\n",
        "      format_instructions_H=format_instructions_H\n",
        "  )\n",
        "  correction_chain_H = correction_prompt_H_fixed | model | parser_H\n",
        "\n",
        "  reply_H = rfh_responses['Helpfulness']['raw']\n",
        "  validated_output_H = correction_chain_H.invoke({\"raw_medgemma_output\": reply_H})\n",
        "  json_string_H = validated_output_H.model_dump_json(indent=4)\n",
        "\n",
        "  return json_string_H\n",
        "\n"
      ],
      "metadata": {
        "id": "dQpLRLGqyXhG"
      },
      "execution_count": 127,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain_core.output_parsers import PydanticOutputParser\n",
        "\n",
        "# 1. Instantiate the reliable OpenAI model\n",
        "gpt_parser_model = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)"
      ],
      "metadata": {
        "id": "thdfdDDsze96"
      },
      "execution_count": 128,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "json_R = get_outputJSON_R(rfh_responses=rfh_responses, model=gpt_parser_model, JudgeOutput_R=JudgeOutput_R)\n",
        "json_F = get_outputJSON_F(rfh_responses=rfh_responses, model=gpt_parser_model, JudgeOutput_F=JudgeOutput_F)\n",
        "json_H = get_outputJSON_H(rfh_responses=rfh_responses, model=gpt_parser_model, JudgeOutput_H=JudgeOutput_H)\n",
        "print(json_R)\n",
        "print(json_F)\n",
        "print(json_H)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7ClauSFMze7G",
        "outputId": "f759f71c-1540-4dd8-d202-41fb36d8a3a3"
      },
      "execution_count": 130,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "    \"user_question\": \"which medication am I taking?\",\n",
            "    \"portal_response\": \"I understand that it can be confusing to keep track of your medications, and I'm here to help you with that. Based on your records, you are currently taking the following medications:\\n\\n1. **Acetaminophen 325 MG Oral Tablet (Tylenol)**\\n2. **Acetaminophen 325 MG / OxyCODONE Hydrochloride 5 MG Oral Tablet**\\n3. **Amlodipine 2.5 MG Oral Tablet**\\n4. **Naproxen Sodium 220 MG Oral Tablet**\\n\\nIf you have any questions about these medications, such as their purposes or how to take them, please feel free to ask. It's important to ensure you feel comfortable and informed about your treatment.\",\n",
            "    \"relevance_score\": 5\n",
            "}\n",
            "{\n",
            "    \"user_question\": \"which medication am I taking?\",\n",
            "    \"portal_response\": \"I understand that it can be confusing to keep track of your medications, and I'm here to help you with that. Based on your records, you are currently taking the following medications:\\n\\n1. **Acetaminophen 325 MG Oral Tablet (Tylenol)**\\n2. **Acetaminophen 325 MG / OxyCODONE Hydrochloride 5 MG Oral Tablet**\\n3. **Amlodipine 2.5 MG Oral Tablet**\\n4. **Naproxen Sodium 220 MG Oral Tablet**\\n\\nIf you have any questions about these medications, such as their purposes or how to take them, please feel free to ask. It's important to ensure you feel comfortable and informed about your treatment.\",\n",
            "    \"faithfulness_score\": 5\n",
            "}\n",
            "{\n",
            "    \"user_question\": \"which medication am I taking?\",\n",
            "    \"portal_response\": \"I understand that it can be confusing to keep track of your medications, and I'm here to help you with that. Based on your records, you are currently taking the following medications:\\n\\n1. **Acetaminophen 325 MG Oral Tablet (Tylenol)**\\n2. **Acetaminophen 325 MG / OxyCODONE Hydrochloride 5 MG Oral Tablet**\\n3. **Amlodipine 2.5 MG Oral Tablet**\\n4. **Naproxen Sodium 220 MG Oral Tablet**\\n\\nIf you have any questions about these medications, such as their purposes or how to take them, please feel free to ask. It's important to ensure you feel comfortable and informed about your treatment.\",\n",
            "    \"helpfulness_score\": 5\n",
            "}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "hoZLiq9bze4S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2RBacg0mze1u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "wqjd150_zezF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "parser_R = PydanticOutputParser(pydantic_object=JudgeOutput_R)\n",
        "format_instructions_R = parser_R.get_format_instructions()\n",
        "print(format_instructions_R)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cQHL3RH5xMCV",
        "outputId": "a8cd2131-2a98-4c37-dda6-704b640a5894"
      },
      "execution_count": 118,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The output should be formatted as a JSON instance that conforms to the JSON schema below.\n",
            "\n",
            "As an example, for the schema {\"properties\": {\"foo\": {\"title\": \"Foo\", \"description\": \"a list of strings\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"foo\"]}\n",
            "the object {\"foo\": [\"bar\", \"baz\"]} is a well-formatted instance of the schema. The object {\"properties\": {\"foo\": [\"bar\", \"baz\"]}} is not well-formatted.\n",
            "\n",
            "Here is the output schema:\n",
            "```\n",
            "{\"description\": \"The final, clean, structured output from the evaluation process.\", \"properties\": {\"user_question\": {\"description\": \"The original question from the patient.\", \"title\": \"User Question\", \"type\": \"string\"}, \"portal_response\": {\"description\": \"The full response provided by the patient-facing system.\", \"title\": \"Portal Response\", \"type\": \"string\"}, \"relevance_score\": {\"description\": \"The final Relevance score (1-5) based on the criteria provided in the prompt.\", \"enum\": [1, 2, 3, 4, 5], \"title\": \"Relevance Score\", \"type\": \"integer\"}}, \"required\": [\"user_question\", \"portal_response\", \"relevance_score\"]}\n",
            "```\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "##Faithfulness json extraction from gpt 40 mini\n",
        "\n",
        "# 2. Get the specific formatting instructions for GPT-4o mini\n",
        "parser_F = PydanticOutputParser(pydantic_object=JudgeOutput_F)\n",
        "format_instructions_F = parser_F.get_format_instructions()\n",
        "\n",
        "correction_prompt_F = ChatPromptTemplate.from_messages([\n",
        "    (\"system\",\n",
        "     \"You are a strict JSON formatter. Your task is to extract the 'User Question', 'Portal Response', and the 'Faithfulness Score' from the RAW TEXT provided below, and reformat it STRICTLY according to the given JSON schema. Output your response as a JSON object.\"),\n",
        "    (\"human\",\n",
        "     \"RAW TEXT (May contain errors, markdown, or extra text):\\n---\\n{raw_medgemma_output}\\n---\\n\\n{format_instructions_F}\") # <-- Still requires this variable\n",
        "])\n",
        "\n",
        "correction_prompt_F_fixed = correction_prompt_F.partial(\n",
        "    format_instructions_F=format_instructions_F\n",
        ")\n",
        "correction_chain_F = correction_prompt_F_fixed | gpt_parser_model | parser_F\n"
      ],
      "metadata": {
        "id": "Jxl-CZ4srtka"
      },
      "execution_count": 104,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##Helpfulness json extraction from gpt 40 mini\n",
        "\n",
        "# 2. Get the specific formatting instructions for GPT-4o mini\n",
        "parser_H = PydanticOutputParser(pydantic_object=JudgeOutput_H)\n",
        "format_instructions_H = parser_H.get_format_instructions()\n",
        "\n",
        "correction_prompt_F = ChatPromptTemplate.from_messages([\n",
        "    (\"system\",\n",
        "     \"You are a strict JSON formatter. Your task is to extract the 'User Question', 'Portal Response', and the 'Helpfulness Score' from the RAW TEXT provided below, and reformat it STRICTLY according to the given JSON schema. Output your response as a JSON object.\"),\n",
        "    (\"human\",\n",
        "     \"RAW TEXT (May contain errors, markdown, or extra text):\\n---\\n{raw_medgemma_output}\\n---\\n\\n{format_instructions_H}\") # <-- Still requires this variable\n",
        "])\n",
        "\n",
        "correction_prompt_H_fixed = correction_prompt_F.partial(\n",
        "    format_instructions_H=format_instructions_H\n",
        ")\n",
        "correction_chain_H = correction_prompt_H_fixed | gpt_parser_model | parser_H"
      ],
      "metadata": {
        "id": "yZkOgsLTsAhd"
      },
      "execution_count": 105,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rfh_responses.keys()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0APEMpMXsufG",
        "outputId": "7b676b4e-52af-4820-d1b4-fc13de1320aa"
      },
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['Relevance', 'Faithfulness', 'Helpfulness'])"
            ]
          },
          "metadata": {},
          "execution_count": 106
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "reply_R = rfh_responses['Relevance']['raw']\n",
        "reply_F = rfh_responses['Faithfulness']['raw']\n",
        "reply_H = rfh_responses['Helpfulness']['raw']"
      ],
      "metadata": {
        "id": "W9Pd6Ib8sBpW"
      },
      "execution_count": 107,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "validated_output_R = correction_chain_R.invoke({\"raw_medgemma_output\": reply_R})\n",
        "validated_output_F = correction_chain_F.invoke({\"raw_medgemma_output\": reply_F})\n",
        "validated_output_H = correction_chain_H.invoke({\"raw_medgemma_output\": reply_H})"
      ],
      "metadata": {
        "id": "KAzB9zWkryKP"
      },
      "execution_count": 108,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "json_string_R = validated_output_R.model_dump_json(indent=4)\n",
        "json_string_F = validated_output_F.model_dump_json(indent=4)\n",
        "json_string_H = validated_output_H.model_dump_json(indent=4)\n"
      ],
      "metadata": {
        "id": "ok4aoXdutKZ1"
      },
      "execution_count": 109,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(json_string_R)\n",
        "print(json_string_F)\n",
        "print(json_string_H)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h_DLhXuWt6xO",
        "outputId": "2ebfba57-8883-4ca8-8587-3f8fa621324b"
      },
      "execution_count": 117,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "    \"user_question\": \"which medication am I taking?\",\n",
            "    \"portal_response\": \"I understand that it can be confusing to keep track of your medications, and I'm here to help you with that. Based on your records, you are currently taking the following medications:\\n\\n1. **Acetaminophen 325 MG Oral Tablet (Tylenol)**\\n2. **Acetaminophen 325 MG / OxyCODONE Hydrochloride 5 MG Oral Tablet**\\n3. **Amlodipine 2.5 MG Oral Tablet**\\n4. **Naproxen Sodium 220 MG Oral Tablet**\\n\\nIf you have any questions about these medications, such as their purposes or how to take them, please feel free to ask. It's important to ensure you feel comfortable and informed about your treatment.\",\n",
            "    \"relevance_score\": 5\n",
            "}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "####towards a pipeline\n",
        "\n",
        "def get_RFH_evaluation(patient_id, user_q):\n",
        "    \"\"\"\n",
        "    for a patient id, user_q, returns RFH JSONs for BOTH\n",
        "    non optimized (empathy) response, and empathy optimized response,\n",
        "    and the empathy optimized score for the optimized response\n",
        "    \"\"\"\n",
        "    payload = create_payload(patient_id,user_q, model=LLM_MODEL)\n",
        "    user_question = user_q\n",
        "    df = payload['df']\n",
        "    portal_response = payload['opt_response']\n",
        "\n",
        "    # payload.keys()\n",
        "    # dict_keys(['sql', 'df', 'non_opt_resp', 'opt_score', 'opt_response'])\n",
        "\n",
        "    RFH4_nonoptresponses = run_judge_prompts(user_question, portal_response=payload['non_opt_resp'], df_as_text=df)\n",
        "    json_R_nonoptresp = get_outputJSON_R(rfh_responses=RFH4_nonoptresponses, model=gpt_parser_model, JudgeOutput_R=JudgeOutput_R)\n",
        "    json_F_nonoptresp = get_outputJSON_F(rfh_responses=RFH4_nonoptresponses, model=gpt_parser_model, JudgeOutput_F=JudgeOutput_F)\n",
        "    json_H_nonoptresp = get_outputJSON_H(rfh_responses=RFH4_nonoptresponses, model=gpt_parser_model, JudgeOutput_H=JudgeOutput_H)\n",
        "\n",
        "    RFH4_optresponses = run_judge_prompts(user_question, portal_response=payload['opt_response'], df_as_text=df)\n",
        "    json_R_optresp = get_outputJSON_R(rfh_responses=RFH4_optresponses, model=gpt_parser_model, JudgeOutput_R=JudgeOutput_R)\n",
        "    json_F_optresp = get_outputJSON_F(rfh_responses=RFH4_optresponses, model=gpt_parser_model, JudgeOutput_F=JudgeOutput_F)\n",
        "    json_H_optresp = get_outputJSON_H(rfh_responses=RFH4_optresponses, model=gpt_parser_model, JudgeOutput_H=JudgeOutput_H)\n",
        "\n",
        "    return {\n",
        "        \"patient_id\": patient_id,\n",
        "        \"user_q\": user_q,\n",
        "        \"empathy_opt_score\": payload['opt_score'],\n",
        "        \"non_opt_RFH\": [json_R_nonoptresp, json_F_nonoptresp, json_H_nonoptresp],\n",
        "        \"opt_RFH\": [json_R_optresp, json_F_optresp, json_H_optresp]\n",
        "    }\n"
      ],
      "metadata": {
        "id": "asmjSSdW8cFB"
      },
      "execution_count": 155,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "patient_id = '0fca905f-391c-08d3-4b93-b53f69b9da53'\n",
        "user_q = 'which medication am I taking?'\n",
        "dict_ = get_RFH_evaluation(patient_id, user_q)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SQugrhkA9Gjd",
        "outputId": "693aab67-9ff4-41ea-9722-8549b5c2849b"
      },
      "execution_count": 156,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- STARTING OPTIMIZATION (Max Retries: 3) ---\n",
            "\n",
            "--- GENERATING RESPONSE (Retry: 0) ---\n",
            "\n",
            "--- EVALUATING RESPONSE ---\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:1 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-> Score: 4/5\n",
            "\n",
            "*** ROUTE: END (Score > 3) ***\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:1 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:1 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:1 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:1 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:1 for open-end generation.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dict_.keys()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OcuQ-RKA9rTh",
        "outputId": "ee4b1239-3c09-4859-df78-71afac095c3d"
      },
      "execution_count": 157,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['patient_id', 'user_q', 'empathy_opt_score', 'non_opt_RFH', 'opt_RFH'])"
            ]
          },
          "metadata": {},
          "execution_count": 157
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "json_string = dict_['non_opt_RFH'][0]\n",
        "python_dict = json.loads(json_string)\n",
        "python_dict"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-A_uEOIoBnhq",
        "outputId": "3f7e546f-c0cf-4098-c097-5807fffdc0aa"
      },
      "execution_count": 165,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'user_question': 'which medication am I taking?',\n",
              " 'portal_response': 'The table shows medication records for patient ID 0fca905f-391c-08d3-4b93-b53f69b9da53, listing five entries. All medications are oral tablets, with dosages provided for Acetaminophen and amLODIPine, while the dosage for Naproxen sodium is missing. Notably, there are no start or end dates, and the refills field is also empty for all entries. The table appears truncated, showing only 5 rows.',\n",
              " 'relevance_score': 4}"
            ]
          },
          "metadata": {},
          "execution_count": 165
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_my_dict(dict_):\n",
        "\n",
        "  d = {\n",
        "    'patient_id': dict_['patient_id'],\n",
        "    'user_question' : dict_['user_q'],\n",
        "    'empathy_opt_score' : dict_['empathy_opt_score'],\n",
        "\n",
        "    'nonopt_R_score'  : json.loads(dict_['non_opt_RFH'][0])['relevance_score'],\n",
        "    'nonopt_F_score'  :  json.loads(dict_['non_opt_RFH'][1])['faithfulness_score'],\n",
        "    'nonopt_H_score'  :  json.loads(dict_['non_opt_RFH'][2])['helpfulness_score'],\n",
        "\n",
        "    'opt_R_score' :  json.loads(dict_['opt_RFH'][0])['relevance_score'],\n",
        "    'opt_F_score' :  json.loads(dict_['opt_RFH'][1])['faithfulness_score'],\n",
        "    'opt_H_score' :  json.loads(dict_['opt_RFH'][2])['helpfulness_score'],\n",
        "\n",
        "    'nonopt_resp'   :  json.loads(dict_['non_opt_RFH'][0])['portal_response'],\n",
        "    'opt_resp'   :  json.loads(dict_['opt_RFH'][0])['portal_response']\n",
        "\n",
        "  }\n",
        "  return d"
      ],
      "metadata": {
        "id": "YjDh-VSj91sT"
      },
      "execution_count": 190,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(extract_my_dict(dict_))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VHFTAZZc-0kh",
        "outputId": "b3955492-0807-41ee-d78f-f8cf83d33ca0"
      },
      "execution_count": 191,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'patient_id': '0fca905f-391c-08d3-4b93-b53f69b9da53', 'user_question': 'which medication am I taking?', 'empathy_opt_score': 4, 'nonopt_R_score': 4, 'nonopt_F_score': 5, 'nonopt_H_score': 2, 'opt_R_score': 5, 'opt_F_score': 5, 'opt_H_score': 5, 'nonopt_resp': 'The table shows medication records for patient ID 0fca905f-391c-08d3-4b93-b53f69b9da53, listing five entries. All medications are oral tablets, with dosages provided for Acetaminophen and amLODIPine, while the dosage for Naproxen sodium is missing. Notably, there are no start or end dates, and the refills field is also empty for all entries. The table appears truncated, showing only 5 rows.', 'opt_resp': \"I understand that it can be a bit confusing to keep track of your medications, and I'm here to help you with that. Based on your records, you are currently taking the following medications:\\n\\n1. **Acetaminophen 325 MG Oral Tablet (Tylenol)**\\n2. **Acetaminophen 325 MG / OxyCODONE Hydrochloride 5 MG Oral Tablet**\\n3. **Amlodipine 2.5 MG Oral Tablet**\\n4. **Naproxen Sodium 220 MG Oral Tablet**\\n\\nIf you have any questions about these medications, such as their purposes or how to take them, please feel free to ask. It's important to feel comfortable and informed about your treatment.\"}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# This is the master file that\n",
        "\n",
        "takes in a patient id, user question,\n",
        "returns\n",
        "\n",
        "*   creates a payload of generate sql, returned df, nonoptimized response, and then empathy optimized response\n",
        "    payload = create_payload(patient_id,user_q, model=LLM_MODEL)\n",
        "    payload.keys()\n",
        "    dict_keys(['sql', 'df', 'non_opt_resp', 'opt_score', 'opt_response'])\n",
        "    \n",
        "*   then calcuates RFH scores of BOTH non optimized and optimized responses using MedGemma, and uses gpt 4o mini to format outputs in a JSON\n",
        "\n",
        "**Pipeline functions**\n",
        "\n",
        "**def get_RFH_evaluation(patient_id, user_q):**\n",
        "\n",
        "\n",
        "    RFH4_nonoptresponses = run_judge_prompts(user_question, portal_response=payload['non_opt_resp'], df_as_text=df)\n",
        "    json_R_nonoptresp = get_outputJSON_R(rfh_responses=RFH4_nonoptresponses, model=gpt_parser_model, JudgeOutput_R=JudgeOutput_R)\n",
        "    json_F_nonoptresp = get_outputJSON_F(rfh_responses=RFH4_nonoptresponses, model=gpt_parser_model, JudgeOutput_F=JudgeOutput_F)\n",
        "    json_H_nonoptresp = get_outputJSON_H(rfh_responses=RFH4_nonoptresponses, model=gpt_parser_model, JudgeOutput_H=JudgeOutput_H)\n",
        "\n",
        "    RFH4_optresponses = run_judge_prompts(user_question, portal_response=payload['opt_response'], df_as_text=df)\n",
        "    json_R_optresp = get_outputJSON_R(rfh_responses=RFH4_optresponses, model=gpt_parser_model, JudgeOutput_R=JudgeOutput_R)\n",
        "    json_F_optresp = get_outputJSON_F(rfh_responses=RFH4_optresponses, model=gpt_parser_model, JudgeOutput_F=JudgeOutput_F)\n",
        "    json_H_optresp = get_outputJSON_H(rfh_responses=RFH4_optresponses, model=gpt_parser_model, JudgeOutput_H=JudgeOutput_H)\n",
        "\n",
        "    return {\n",
        "        \"patient_id\": patient_id,\n",
        "        \"user_q\": user_q,\n",
        "        \"empathy_opt_score\": payload['opt_score'],\n",
        "        \"non_opt_RFH\": [json_R_nonoptresp, json_F_nonoptresp, json_H_nonoptresp],\n",
        "        \"opt_RFH\": [json_R_optresp, json_F_optresp, json_H_optresp]\n",
        "    }\n",
        "\n",
        "\n",
        "\n",
        "**then use extract_my_dict(dict_) to get:**\n",
        "\n",
        "    {\n",
        "      'patient_id': '0fca905f-391c-08d3-4b93-b53f69b9da53',\n",
        "      'user_question': 'which medication am I taking?',\n",
        "      'empathy_opt_score': 4,\n",
        "      \n",
        "      'nonopt_R_score': 4,\n",
        "      'nonopt_F_score': 5,\n",
        "      'nonopt_H_score': 2,\n",
        "      \n",
        "      'opt_R_score': 5,\n",
        "      'opt_F_score': 5,\n",
        "      'opt_H_score': 5,\n",
        "      \n",
        "      'nonopt_resp':\n",
        "          'The table shows medication records for patient ID 0fca905f-391c-08d3-4b93-b53f69b9da53, listing five entries. All medications are oral tablets, with dosages provided for Acetaminophen and amLODIPine, while the dosage for Naproxen sodium is missing. Notably, there are no start or end dates, and the refills field is also empty for all entries. The table appears truncated, showing only 5 rows.',\n",
        "      \n",
        "      'opt_resp':\n",
        "          \"I understand that it can be a bit confusing to keep track of your medications, and I'm here to help you with that. Based on your records, you are currently taking the following medications:\\n\\n1. **Acetaminophen 325 MG Oral Tablet (Tylenol)**\\n2. **Acetaminophen 325 MG / OxyCODONE Hydrochloride 5 MG Oral Tablet**\\n3. **Amlodipine 2.5 MG Oral Tablet**\\n4. **Naproxen Sodium 220 MG Oral Tablet**\\n\\nIf you have any questions about these medications, such as their purposes or how to take them, please feel free to ask. It's important to feel comfortable and informed about your treatment.\"\n",
        "\n",
        "    }\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "hPCBt1efIQge"
      }
    }
  ]
}